{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:38:14.772193Z",
     "start_time": "2023-06-06T17:38:12.046360Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/arberimbibaj/dataset_example_indicatorCATE.csv', header=None, index_col=[0])\n",
    "data = data.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:38:15.969573Z",
     "start_time": "2023-06-06T17:38:15.936330Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "d = len(data[0,:]) - 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:38:18.340883Z",
     "start_time": "2023-06-06T17:38:18.318954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# train test split\n",
    "random.shuffle(data)\n",
    "training, test = data[:700,:], data[700:,:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:38:18.685014Z",
     "start_time": "2023-06-06T17:38:18.663380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# slice dataset by treatment status\n",
    "training_control = training[training[:,26]==0]\n",
    "training_treatment = training[training[:,26]==1]\n",
    "\n",
    "# slice test set by treatment status\n",
    "test_control = test[test[:,26]==0]\n",
    "test_treatment = test[test[:,26]==1]\n",
    "\n",
    "# Y_train by treatment status\n",
    "Y_train_control = training_control[:,0]\n",
    "Y_train_treatment = training_treatment[:,0]\n",
    "\n",
    "# Y_test by treatment status\n",
    "Y_test_control = test_control[:,0]\n",
    "Y_test_treatment = test_treatment[:,0]\n",
    "\n",
    "# X_train by treatment status\n",
    "X_train_control = training_control[:,1:26]\n",
    "X_train_treatment = training_treatment[:,1:26]\n",
    "\n",
    "# X_test by treatment status\n",
    "X_test_control = test_control[:,1:26]\n",
    "X_test_treatment = test_treatment[:,1:26]\n",
    "\n",
    "# X and Y test\n",
    "X_test = test[:,1:26]\n",
    "Y_test = test[:,0]\n",
    "\n",
    "# X_train and Y_train (no split by treatment status)\n",
    "X_train = training[:,1:26]\n",
    "Y_train = training[:,0]\n",
    "\n",
    "# W_train and W_test\n",
    "W_train = training[:,26]\n",
    "W_test = test[:,26]\n",
    "\n",
    "# tau_test\n",
    "tau_test = test[:,27]\n",
    "tau_test_control = test_control[:,27]\n",
    "tau_test_treatment = test_treatment[:,27]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:38:19.144378Z",
     "start_time": "2023-06-06T17:38:19.129179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# set training and test features for the S-Learner (it views W as no different from other X's)\n",
    "X_W_train = training[:,1:27]\n",
    "X_W_test = test[:,1:27]\n",
    "X_test_0 = np.concatenate((test[:,1:26],np.zeros((300,1))), axis=1)\n",
    "X_test_1 = np.concatenate((test[:,1:26],np.ones((300,1))), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T17:38:20.093199Z",
     "start_time": "2023-06-06T17:38:19.997049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_control"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_treatment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train_control"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train_treatment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tau_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# T-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# T-Learner (example with Random Forest)\n",
    "\n",
    "# mu_0\n",
    "t_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "t_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "t_mu_0_hat = t_learner_mu0.predict(X_test)\n",
    "\n",
    "# mu_1\n",
    "t_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "t_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "t_mu_1_hat = t_learner_mu1.predict(X_test)\n",
    "# Prediction = mu_1 - mu_0\n",
    "t_tau_hat = t_mu_1_hat - t_mu_0_hat\n",
    "t_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((t_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# S-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### S-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S-learner (example with Random Forest)\n",
    "\n",
    "# mu_x\n",
    "s_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "s_learner.fit(X_W_train,Y_train)\n",
    "\n",
    "# mu_0_hat\n",
    "s_mu_0_hat = s_learner.predict(X_test_0)\n",
    "\n",
    "# mu_1_hat\n",
    "s_mu_1_hat = s_learner.predict(X_test_1)\n",
    "\n",
    "# tau_hat\n",
    "s_tau_hat = s_mu_1_hat - s_mu_0_hat\n",
    "s_tau_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((s_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# X-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### X-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# compute imputed treatment effect D_0 and D_1\n",
    "# d_0\n",
    "imputed_0 = x_learner_mu1.predict(X_train_control) - Y_train_control\n",
    "\n",
    "# d_1\n",
    "imputed_1 = Y_train_treatment - x_learner_mu0.predict(X_train_treatment)\n",
    "\n",
    "# regress imputed on X\n",
    "# tau_hat_0\n",
    "x_tau_0_hat = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_tau_0_hat.fit(X_train_control ,imputed_0)\n",
    "\n",
    "# tau_hat_1\n",
    "x_tau_1_hat = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_tau_1_hat.fit(X_train_treatment ,imputed_1)\n",
    "\n",
    "# estimate e_x to use as g_x\n",
    "g_x_hat = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "g_x_hat.fit(X_train,W_train)\n",
    "probabilities = g_x_hat.predict_proba(X_test)\n",
    "probas_1 = probabilities[:,1]\n",
    "probas_0 = probabilities[:,0]\n",
    "\n",
    "# final estimator of tau\n",
    "x_tau_hat = probas_1 * x_tau_0_hat.predict(X_test) + probas_0 * x_tau_1_hat.predict(X_test)\n",
    "x_tau_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error (much lower here!)\n",
    "((x_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# R-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### R-Learner\n",
    "\n",
    "# estimate e_x\n",
    "r_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "r_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# get e_x predictions\n",
    "r_probas = r_learner_e_x.predict_proba(X_train)\n",
    "r_probas_0 = r_probas[:,0] # probabilities of W=0\n",
    "r_probas_1 = r_probas[:,1] # probabilities of W=1\n",
    "\n",
    "# estimate mu_x\n",
    "r_learner_mu_x = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "r_learner_mu_x.fit(X_train,Y_train)\n",
    "\n",
    "# compute r-pseudo-outcome and weights\n",
    "r_learner_pseudo_outcomes = (Y_train - r_learner_mu_x.predict(X_train)) / (W_train - r_probas_1)\n",
    "r_learner_weights = (W_train - r_probas_1)**2\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X, weight by (W-e(x))^2)\n",
    "r_learner_tau = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "r_learner_tau.fit(X_train,r_learner_pseudo_outcomes, sample_weight=r_learner_weights)\n",
    "\n",
    "# predict tau\n",
    "r_tau_hats = r_learner_tau.predict(X_test)\n",
    "r_tau_hats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((r_tau_hats - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DR-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### DR-Learner\n",
    "\n",
    "# TODO: APPLY CROSS-FITTING?\n",
    "# estimate e_x\n",
    "dr_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "dr_learner_e_x.fit(X_train, W_train)\n",
    "\n",
    "dr_probas = dr_learner_e_x.predict_proba(X_train)\n",
    "dr_probas_0 = dr_probas[:,0] # probabilities of W=0\n",
    "dr_probas_1 = dr_probas[:,1] # probabilities of W=1\n",
    "\n",
    "# estimate mu_0\n",
    "dr_learner_mu_0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "dr_learner_mu_0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# estimate mu_1\n",
    "dr_learner_mu_1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "dr_learner_mu_1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# DR-pseudo-outcomes\n",
    "mu_w = W_train * dr_learner_mu_1.predict(X_train) + (1 - W_train) * dr_learner_mu_0.predict(X_train) # this is mu_w for each observation, i.e mu_1 for units in the treatment groups, and mu_0 for units in the control group\n",
    "dr_pseudo_outcomes = (W_train - dr_probas_1) / (dr_probas_1 * dr_probas_0) * (Y_train - mu_w) + dr_learner_mu_1.predict(X_train) - dr_learner_mu_0.predict(X_train)\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X) # TODO: USE \"Test Set\" for this estimation\n",
    "dr_learner_tau_hat = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "dr_learner_tau_hat.fit(X_train,dr_pseudo_outcomes)\n",
    "\n",
    "# predict tau\n",
    "dr_tau_hat = dr_learner_tau_hat.predict(X_test)\n",
    "dr_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((dr_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RA-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### RA-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "ra_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "ra_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "ra_pseudo_outcome = W_train*(Y_train - ra_learner_mu0.predict(X_train)) + (1 - W_train)*(ra_learner_mu1.predict(X_train) - Y_train)\n",
    "\n",
    "# tau_hat\n",
    "ra_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_tau_hat_learner.fit(X_train, ra_pseudo_outcome)\n",
    "ra_tau_hat = ra_tau_hat_learner.predict(X_test)\n",
    "ra_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((ra_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PW-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### PW-Learner\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "pw_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "pw_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "pw_pseudo_outcome = (W_train/pw_learner_e_x.predict_proba(X_train)[:,1] - (1 - W_train)/(pw_learner_e_x.predict_proba(X_train)[:,0]))*Y_train\n",
    "\n",
    "# tau_hat\n",
    "pw_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_tau_hat_learner.fit(X_train, pw_pseudo_outcome)\n",
    "pw_tau_hat = pw_tau_hat_learner.predict(X_test)\n",
    "pw_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((pw_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# F-Learner: AKA THE SAME AS PW-LEARNER!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### F-Learner\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "f_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "f_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "f_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "f_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "f_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "f_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "f_pseudo_outcome = (W_train/f_learner_e_x.predict_proba(X_train)[:,1] - (1 - W_train)/(f_learner_e_x.predict_proba(X_train)[:,0]))*Y_train\n",
    "\n",
    "# tau_hat\n",
    "f_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "f_tau_hat_learner.fit(X_train, pw_pseudo_outcome)\n",
    "f_tau_hat = f_tau_hat_learner.predict(X_test)\n",
    "f_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "print(((f_tau_hat - tau_test)**2).mean())\n",
    "print(\"Same as for PW-Learner\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# U-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### U-Learner\n",
    "# estimate e_x\n",
    "u_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "u_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# estimate mu_x\n",
    "u_learner_mu_x = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "u_learner_mu_x.fit(X_train,Y_train)\n",
    "\n",
    "# compute residuals\n",
    "u_learner_residuals = (Y_train - u_learner_mu_x.predict(X_train))/(W_train - u_learner_e_x.predict_proba(X_train)[:,1])\n",
    "\n",
    "# tau_hat - regress residuals on X\n",
    "u_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "u_tau_hat_learner.fit(X_train,u_learner_residuals)\n",
    "\n",
    "u_tau_hats = u_tau_hat_learner.predict(X_test)\n",
    "u_tau_hats\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((u_tau_hats - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Just some lasso tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "poly_train = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_train = poly_train.fit_transform(X_train)\n",
    "poly_test = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test = poly_test.fit_transform(X_test)\n",
    "X_poly_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lasso_poly = LassoCV(cv=10, random_state=0, tol=1e-2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# degree 3: 10 seconds to fit (100% cpu)\n",
    "# degree 4: 90 seconds to fit (100% cpu)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predictions = lasso_poly.predict(X_poly_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((y_predictions - Y_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# just some Neural Network test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make model\n",
    "# 3 layers with 200 units (elu activation), 2 layers with 100 units (elu activations), 1 output layer (linear activation)\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(d,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"linear\", name=\"layer6\"),\n",
    "\n",
    "], name=\"Dense_Neural_Network\")\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, start_from_epoch=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training Model\")\n",
    "training = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=100,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[callback] # include early stopping\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Generate predictions for test samples\")\n",
    "predictions = np.reshape(model.predict(X_test),(300,))\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((predictions - Y_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRY SAME WITH LASSO AND NEURAL NETWORK!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## With Lasso (or L1-loss for logistic regression)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_train = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_train = poly_train.fit_transform(X_train)\n",
    "poly_test = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test = poly_test.fit_transform(X_test)\n",
    "X_poly_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute polynomial features for treatment and control groups in training set\n",
    "poly_train_treatment = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_train_treatment = poly_train_treatment.fit_transform(X_train_treatment)\n",
    "poly_train_control = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_train_control = poly_train_treatment.fit_transform(X_train_control)\n",
    "poly_test = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test = poly_test.fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_poly_train_control"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_poly_train_treatment\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## T-learner Lasso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# T-Learner (example with Lasso)\n",
    "tic = time.perf_counter()\n",
    "# mu_0\n",
    "t_learner_mu0 = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "t_learner_mu0.fit(X_poly_train_control,Y_train_control)\n",
    "t_mu_0_hat = t_learner_mu0.predict(X_poly_test)\n",
    "\n",
    "# mu_1\n",
    "t_learner_mu1 = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "t_learner_mu1.fit(X_poly_train_treatment,Y_train_treatment)\n",
    "t_mu_1_hat = t_learner_mu1.predict(X_poly_test)\n",
    "\n",
    "# Prediction = mu_1 - mu_0\n",
    "t_tau_hat = t_mu_1_hat - t_mu_0_hat\n",
    "toc = time.perf_counter()\n",
    "t_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Time for calculations: {toc-tic}') # took 69 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((t_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## S-learner Lasso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute polynomial features for treatment and control groups in training set\n",
    "xw_poly_train = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_W_poly_train = poly_train_treatment.fit_transform(X_W_train)\n",
    "\n",
    "xw_poly_test_0 = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test_0 = xw_poly_test_0.fit_transform(X_test_0)\n",
    "\n",
    "xw_poly_test_1 = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test_1 = xw_poly_test_0.fit_transform(X_test_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S-learner (example with Random Forest)\n",
    "tic = time.perf_counter()\n",
    "# mu_x\n",
    "s_learner = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "s_learner.fit(X_W_poly_train,Y_train)\n",
    "\n",
    "# mu_0_hat\n",
    "s_mu_0_hat = s_learner.predict(X_poly_test_0)\n",
    "\n",
    "# mu_1_hat\n",
    "s_mu_1_hat = s_learner.predict(X_poly_test_1)\n",
    "\n",
    "# tau_hat\n",
    "s_tau_hat = s_mu_1_hat - s_mu_0_hat\n",
    "toc = time.perf_counter()\n",
    "print(f'Time for computation: {toc-tic}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((s_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## X-learner with lasso (or l1-penalty)\n",
    "### TAKES A LOT OF TIME!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### X-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_learner_mu0.fit(X_poly_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_learner_mu1.fit(X_poly_train_treatment,Y_train_treatment)\n",
    "\n",
    "# compute imputed treatment effect D_0 and D_1\n",
    "# d_0\n",
    "imputed_0 = x_learner_mu1.predict(X_poly_train_control) - Y_train_control\n",
    "\n",
    "# d_1\n",
    "imputed_1 = Y_train_treatment - x_learner_mu0.predict(X_poly_train_treatment)\n",
    "\n",
    "# regress imputed on X\n",
    "# tau_hat_0\n",
    "x_tau_0_hat = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_tau_0_hat.fit(X_poly_train_control ,imputed_0)\n",
    "\n",
    "# tau_hat_1\n",
    "x_tau_1_hat = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_tau_1_hat.fit(X_poly_train_treatment ,imputed_1)\n",
    "\n",
    "# estimate e_x to use as g_x\n",
    "g_x_hat = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "g_x_hat.fit(X_poly_train,W_train)\n",
    "probabilities = g_x_hat.predict_proba(X_poly_test)\n",
    "probas_1 = probabilities[:,1]\n",
    "probas_0 = probabilities[:,0]\n",
    "\n",
    "# final estimator of tau\n",
    "x_tau_hat = probas_1 * x_tau_0_hat.predict(X_poly_test) + probas_0 * x_tau_1_hat.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc-tic}') # 127 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((x_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## R-learner with lasso (or l1-penalty)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### R-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# estimate e_x\n",
    "r_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "r_learner_e_x.fit(X_poly_train,W_train)\n",
    "\n",
    "# get e_x predictions\n",
    "r_probas = r_learner_e_x.predict_proba(X_poly_train)\n",
    "r_probas_0 = r_probas[:,0] # probabilities of W=0\n",
    "r_probas_1 = r_probas[:,1] # probabilities of W=1\n",
    "\n",
    "# estimate mu_x\n",
    "r_learner_mu_x = LassoCV(cv=10, tol=1, random_state=0)\n",
    "r_learner_mu_x.fit(X_poly_train,Y_train)\n",
    "\n",
    "# compute r-pseudo-outcome and weights\n",
    "r_learner_pseudo_outcomes = (Y_train - r_learner_mu_x.predict(X_poly_train)) / (W_train - r_probas_1)\n",
    "r_learner_weights = (W_train - r_probas_1)**2\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X, weight by (W-e(x))^2)\n",
    "r_learner_tau = LassoCV(cv=10, tol=1, random_state=0)\n",
    "r_learner_tau.fit(X_poly_train,r_learner_pseudo_outcomes, sample_weight=r_learner_weights)\n",
    "\n",
    "# predict tau\n",
    "r_tau_hats = r_learner_tau.predict(X_poly_test)\n",
    "r_tau_hats\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc-tic} seconds') # 98 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((r_tau_hats - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dr-learner with lasso (l1-penalty)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### DR-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# TODO: APPLY CROSS-FITTING?\n",
    "# estimate e_x\n",
    "dr_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "dr_learner_e_x.fit(X_poly_train, W_train)\n",
    "\n",
    "dr_probas = dr_learner_e_x.predict_proba(X_poly_train)\n",
    "dr_probas_0 = dr_probas[:,0] # probabilities of W=0\n",
    "dr_probas_1 = dr_probas[:,1] # probabilities of W=1\n",
    "\n",
    "# estimate mu_0\n",
    "dr_learner_mu_0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "dr_learner_mu_0.fit(X_poly_train_control,Y_train_control)\n",
    "\n",
    "# estimate mu_1\n",
    "dr_learner_mu_1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "dr_learner_mu_1.fit(X_poly_train_treatment,Y_train_treatment)\n",
    "\n",
    "# DR-pseudo-outcomes\n",
    "mu_w = W_train * dr_learner_mu_1.predict(X_poly_train) + (1 - W_train) * dr_learner_mu_0.predict(X_poly_train) # this is mu_w for each observation, i.e mu_1 for units in the treatment groups, and mu_0 for units in the control group\n",
    "dr_pseudo_outcomes = (W_train - dr_probas_1) / (dr_probas_1 * dr_probas_0) * (Y_train - mu_w) + dr_learner_mu_1.predict(X_poly_train) - dr_learner_mu_0.predict(X_poly_train)\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X) # TODO: USE \"Test Set\" for this estimation\n",
    "dr_learner_tau_hat = LassoCV(cv=10, tol=1, random_state=0)\n",
    "dr_learner_tau_hat.fit(X_poly_train,dr_pseudo_outcomes)\n",
    "\n",
    "# predict tau\n",
    "dr_tau_hat = dr_learner_tau_hat.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time needed for computation: {toc-tic} seconds') # 104 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((dr_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ra-learner with lasso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### RA-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "ra_learner_mu0.fit(X_poly_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "ra_learner_mu1.fit(X_poly_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "ra_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "ra_learner_e_x.fit(X_poly_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "ra_pseudo_outcome = W_train*(Y_train - ra_learner_mu0.predict(X_poly_train)) + (1 - W_train)*(ra_learner_mu1.predict(X_poly_train) - Y_train)\n",
    "\n",
    "# tau_hat\n",
    "ra_tau_hat_learner = LassoCV(cv=10, tol=1, random_state=0)\n",
    "ra_tau_hat_learner.fit(X_poly_train, ra_pseudo_outcome)\n",
    "ra_tau_hat = ra_tau_hat_learner.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc-tic} seconds.') # 121 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((ra_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PW-learner with lasso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### PW-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "pw_learner_mu0.fit(X_poly_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "pw_learner_mu1.fit(X_poly_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "pw_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "pw_learner_e_x.fit(X_poly_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "pw_pseudo_outcome = (W_train/pw_learner_e_x.predict_proba(X_poly_train)[:,1] - (1 - W_train)/(pw_learner_e_x.predict_proba(X_poly_train)[:,0]))*Y_train\n",
    "\n",
    "# tau_hat\n",
    "pw_tau_hat_learner = LassoCV(cv=10, tol=1, random_state=0)\n",
    "pw_tau_hat_learner.fit(X_poly_train, pw_pseudo_outcome)\n",
    "pw_tau_hat = pw_tau_hat_learner.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc-tic} seconds.') # 117 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((pw_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## U-learner with lasso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### U-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# estimate e_x\n",
    "u_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "u_learner_e_x.fit(X_poly_train,W_train)\n",
    "\n",
    "# estimate mu_x\n",
    "u_learner_mu_x = LassoCV(cv=10, tol=1, random_state=0)\n",
    "u_learner_mu_x.fit(X_poly_train,Y_train)\n",
    "\n",
    "# compute residuals\n",
    "u_learner_residuals = (Y_train - u_learner_mu_x.predict(X_poly_train))/(W_train - u_learner_e_x.predict_proba(X_poly_train)[:,1])\n",
    "\n",
    "# tau_hat - regress residuals on X\n",
    "u_tau_hat_learner = LassoCV(cv=10, tol=1, random_state=0)\n",
    "u_tau_hat_learner.fit(X_poly_train,u_learner_residuals)\n",
    "\n",
    "u_tau_hats = u_tau_hat_learner.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc-tic} seconds.') # 98 seconds\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((u_tau_hats - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# now do it with neural networks\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# make model\n",
    "# 3 layers with 200 units (elu activation), 2 layers with 100 units (elu activations), 1 output layer (linear activation)\n",
    "model_25 = keras.Sequential([\n",
    "    keras.Input(shape=(25,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"linear\", name=\"layer6\"),\n",
    "\n",
    "], name=\"Dense_Neural_Network\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:01.373095Z",
     "start_time": "2023-06-06T19:11:01.316839Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_25.compile(\n",
    "    optimizer=keras.optimizers.Adam(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:01.502611Z",
     "start_time": "2023-06-06T19:11:01.411220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# save initial weights\n",
    "model_25.save_weights('model_25')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:01.615721Z",
     "start_time": "2023-06-06T19:11:01.562550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "# same model, but input shape=26, for t-learner only\n",
    "# 3 layers with 200 units (elu activation), 2 layers with 100 units (elu activations), 1 output layer (linear activation)\n",
    "model_26 = keras.Sequential([\n",
    "    keras.Input(shape=(26,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"linear\", name=\"layer6\"),\n",
    "\n",
    "], name=\"Dense_Neural_Network\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:01.719795Z",
     "start_time": "2023-06-06T19:11:01.696770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_26.compile(\n",
    "    optimizer=keras.optimizers.Adam(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:01.882316Z",
     "start_time": "2023-06-06T19:11:01.864757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "model_26.save_weights('model_26')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:02.303389Z",
     "start_time": "2023-06-06T19:11:02.289613Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "model_ex = keras.Sequential([\n",
    "    keras.Input(shape=(25,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"relu\", name=\"layer6\"),\n",
    "\n",
    "], name=\"Dense_Neural_Network_Classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:02.474879Z",
     "start_time": "2023-06-06T19:11:02.430994Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_ex.compile(\n",
    "    optimizer=keras.optimizers.Adam(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.5),\n",
    "    # List of metrics to monitor\n",
    "    metrics=keras.metrics.BinaryAccuracy(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:02.613803Z",
     "start_time": "2023-06-06T19:11:02.597652Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "model_ex.save_weights('model_ex')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:02.994807Z",
     "start_time": "2023-06-06T19:11:02.976331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, start_from_epoch=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:11:03.582899Z",
     "start_time": "2023-06-06T19:11:03.567014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# T-Learner (example with Random Forest)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0\n",
    "t_learner_mu0 = model_25\n",
    "print('Training mu0')\n",
    "t_learner_mu0.fit(X_train_control,Y_train_control,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "t_mu_0_hat = t_learner_mu0.predict(X_test)\n",
    "\n",
    "# mu_1\n",
    "model_25.load_weights('model_25')\n",
    "t_learner_mu1 = model_25\n",
    "print('Training mu1')\n",
    "t_learner_mu1.fit(X_train_treatment,Y_train_treatment,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "t_mu_1_hat = t_learner_mu1.predict(X_test)\n",
    "\n",
    "# Prediction = mu_1 - mu_0\n",
    "t_tau_hat = t_mu_1_hat - t_mu_0_hat\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc-tic} seconds.') # 3 seconds\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(t_tau_hat,(300,)) - tau_test)**2).mean() # 3.7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## S-learner with NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S-learner (example with Random Forest)\n",
    "\n",
    "# mu_x\n",
    "model_26.load_weights('model_26')\n",
    "s_learner = model_26\n",
    "s_learner.fit(X_W_train,Y_train,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_W_test, Y_test),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "\n",
    "# mu_0_hat\n",
    "s_mu_0_hat = s_learner.predict(X_test_0)\n",
    "\n",
    "# mu_1_hat\n",
    "s_mu_1_hat = s_learner.predict(X_test_1)\n",
    "\n",
    "# tau_hat\n",
    "s_tau_hat = s_mu_1_hat - s_mu_0_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(s_tau_hat,(300,)) - tau_test)**2).mean() # 2.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# X-learner with Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### X-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "model_25.load_weights('model_25')\n",
    "x_learner_mu0 = model_25\n",
    "x_learner_mu0.fit(X_train_control,Y_train_control,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_control, Y_test_control),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "\n",
    "# d_1\n",
    "imputed_1 = Y_train_treatment - np.reshape(x_learner_mu0.predict(X_train_treatment),(len(Y_train_treatment),))\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "model_25.load_weights('model_25')\n",
    "x_learner_mu1 = model_25\n",
    "x_learner_mu1.fit(X_train_treatment,Y_train_treatment,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_treatment, Y_test_treatment),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "\n",
    "# d_0\n",
    "imputed_0 = np.reshape(x_learner_mu1.predict(X_train_control),(len(Y_train_control),)) - Y_train_control\n",
    "\n",
    "\n",
    "# regress imputed on X\n",
    "\n",
    "# tau_hat_1\n",
    "model_25.load_weights('model_25')\n",
    "x_tau_1_hat = model_25\n",
    "x_tau_1_hat.fit(X_train_treatment,imputed_1,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_treatment, tau_test_treatment),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "\n",
    "x_tau_1_hat_predicts = x_tau_1_hat.predict(X_test)\n",
    "\n",
    "# tau_hat_0\n",
    "model_25.load_weights('model_25')\n",
    "x_tau_0_hat = model_25\n",
    "x_tau_0_hat.fit(X_train_control,imputed_0,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_control, tau_test_control),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "\n",
    "x_tau_0_hat_predicts = x_tau_0_hat.predict(X_test)\n",
    "\n",
    "# estimate e_x to use as g_x\n",
    "model_ex.load_weights('model_ex')\n",
    "g_x_hat = model_ex\n",
    "g_x_hat.fit(X_train,W_train,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, W_test),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "probabilities = g_x_hat.predict(X_test)\n",
    "probas_1 = probabilities\n",
    "probas_0 = 1 - probabilities\n",
    "\n",
    "# final estimator of tau\n",
    "x_tau_hat = probas_1 * x_tau_0_hat_predicts + probas_0 * x_tau_1_hat_predicts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(x_tau_hat,(300,)) - tau_test)**2).mean() # 3! LOL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Do the rest now!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# And the do classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# R-learner with NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6549 - binary_accuracy: 0.7757 - val_loss: 0.7255 - val_binary_accuracy: 0.5467\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6558 - binary_accuracy: 0.7757 - val_loss: 0.7174 - val_binary_accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6554 - binary_accuracy: 0.7714 - val_loss: 0.7247 - val_binary_accuracy: 0.5200\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6545 - binary_accuracy: 0.7786 - val_loss: 0.7178 - val_binary_accuracy: 0.5233\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6547 - binary_accuracy: 0.7843 - val_loss: 0.7181 - val_binary_accuracy: 0.5233\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6543 - binary_accuracy: 0.7857 - val_loss: 0.7269 - val_binary_accuracy: 0.5167\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.7914 - val_loss: 0.7161 - val_binary_accuracy: 0.5433\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6533 - binary_accuracy: 0.7871 - val_loss: 0.7291 - val_binary_accuracy: 0.5400\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.7943 - val_loss: 0.7120 - val_binary_accuracy: 0.5533\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6525 - binary_accuracy: 0.7943 - val_loss: 0.7245 - val_binary_accuracy: 0.5500\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6525 - binary_accuracy: 0.7943 - val_loss: 0.7207 - val_binary_accuracy: 0.5300\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.7971 - val_loss: 0.7199 - val_binary_accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6523 - binary_accuracy: 0.7914 - val_loss: 0.7242 - val_binary_accuracy: 0.5433\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.7957 - val_loss: 0.7182 - val_binary_accuracy: 0.5400\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.7943 - val_loss: 0.7241 - val_binary_accuracy: 0.5367\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6519 - binary_accuracy: 0.7971 - val_loss: 0.7146 - val_binary_accuracy: 0.5367\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6524 - binary_accuracy: 0.7929 - val_loss: 0.7270 - val_binary_accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.7957 - val_loss: 0.7201 - val_binary_accuracy: 0.5400\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6518 - binary_accuracy: 0.7971 - val_loss: 0.7171 - val_binary_accuracy: 0.5267\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6523 - binary_accuracy: 0.7914 - val_loss: 0.7279 - val_binary_accuracy: 0.5200\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6526 - binary_accuracy: 0.7943 - val_loss: 0.7111 - val_binary_accuracy: 0.5400\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6533 - binary_accuracy: 0.7857 - val_loss: 0.7355 - val_binary_accuracy: 0.5200\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6547 - binary_accuracy: 0.7800 - val_loss: 0.7105 - val_binary_accuracy: 0.5300\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6545 - binary_accuracy: 0.7814 - val_loss: 0.7295 - val_binary_accuracy: 0.5233\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6538 - binary_accuracy: 0.7829 - val_loss: 0.7206 - val_binary_accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6535 - binary_accuracy: 0.7886 - val_loss: 0.7139 - val_binary_accuracy: 0.5533\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6536 - binary_accuracy: 0.7829 - val_loss: 0.7242 - val_binary_accuracy: 0.5467\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6529 - binary_accuracy: 0.7914 - val_loss: 0.7168 - val_binary_accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.7929 - val_loss: 0.7210 - val_binary_accuracy: 0.5300\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6527 - binary_accuracy: 0.7914 - val_loss: 0.7218 - val_binary_accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6532 - binary_accuracy: 0.7957 - val_loss: 0.7190 - val_binary_accuracy: 0.5367\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6546 - binary_accuracy: 0.7714 - val_loss: 0.7211 - val_binary_accuracy: 0.5167\n",
      "22/22 [==============================] - 0s 434us/step\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 162.8109 - mean_squared_error: 162.8109 - val_loss: 219.9214 - val_mean_squared_error: 219.9214\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 160.5974 - mean_squared_error: 160.5974 - val_loss: 217.0381 - val_mean_squared_error: 217.0381\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 158.2697 - mean_squared_error: 158.2697 - val_loss: 213.6574 - val_mean_squared_error: 213.6574\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 155.0546 - mean_squared_error: 155.0546 - val_loss: 208.6829 - val_mean_squared_error: 208.6829\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 150.2373 - mean_squared_error: 150.2373 - val_loss: 200.1362 - val_mean_squared_error: 200.1362\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 141.5523 - mean_squared_error: 141.5523 - val_loss: 184.1684 - val_mean_squared_error: 184.1684\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 125.6583 - mean_squared_error: 125.6583 - val_loss: 150.9131 - val_mean_squared_error: 150.9131\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 94.9363 - mean_squared_error: 94.9363 - val_loss: 98.3938 - val_mean_squared_error: 98.3938\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 65.2363 - mean_squared_error: 65.2363 - val_loss: 63.7410 - val_mean_squared_error: 63.7410\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 53.0887 - mean_squared_error: 53.0887 - val_loss: 50.5560 - val_mean_squared_error: 50.5560\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 37.9127 - mean_squared_error: 37.9127 - val_loss: 35.2522 - val_mean_squared_error: 35.2522\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 26.7336 - mean_squared_error: 26.7336 - val_loss: 23.4771 - val_mean_squared_error: 23.4771\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 18.6443 - mean_squared_error: 18.6443 - val_loss: 17.9398 - val_mean_squared_error: 17.9398\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 14.8189 - mean_squared_error: 14.8189 - val_loss: 14.9853 - val_mean_squared_error: 14.9853\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.8794 - mean_squared_error: 12.8794 - val_loss: 13.9861 - val_mean_squared_error: 13.9861\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.7831 - mean_squared_error: 12.7831 - val_loss: 14.0901 - val_mean_squared_error: 14.0901\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.0285 - mean_squared_error: 12.0285 - val_loss: 15.5885 - val_mean_squared_error: 15.5885\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 12.0050 - mean_squared_error: 12.0050 - val_loss: 13.7322 - val_mean_squared_error: 13.7322\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 11.5849 - mean_squared_error: 11.5849 - val_loss: 13.2058 - val_mean_squared_error: 13.2058\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.5914 - mean_squared_error: 11.5914 - val_loss: 12.5165 - val_mean_squared_error: 12.5165\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.4310 - mean_squared_error: 10.4310 - val_loss: 13.3517 - val_mean_squared_error: 13.3517\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.5013 - mean_squared_error: 10.5013 - val_loss: 11.8650 - val_mean_squared_error: 11.8650\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.0885 - mean_squared_error: 10.0885 - val_loss: 13.3304 - val_mean_squared_error: 13.3304\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.9148 - mean_squared_error: 9.9148 - val_loss: 11.9810 - val_mean_squared_error: 11.9810\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.8567 - mean_squared_error: 9.8567 - val_loss: 14.4983 - val_mean_squared_error: 14.4983\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.8467 - mean_squared_error: 10.8467 - val_loss: 14.1654 - val_mean_squared_error: 14.1654\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.8441 - mean_squared_error: 9.8441 - val_loss: 12.8949 - val_mean_squared_error: 12.8949\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.3605 - mean_squared_error: 9.3605 - val_loss: 12.0894 - val_mean_squared_error: 12.0894\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.1273 - mean_squared_error: 9.1273 - val_loss: 11.6785 - val_mean_squared_error: 11.6785\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.9867 - mean_squared_error: 8.9867 - val_loss: 12.2241 - val_mean_squared_error: 12.2241\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.9061 - mean_squared_error: 8.9061 - val_loss: 12.5860 - val_mean_squared_error: 12.5860\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.1826 - mean_squared_error: 9.1826 - val_loss: 13.5191 - val_mean_squared_error: 13.5191\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.0991 - mean_squared_error: 9.0991 - val_loss: 12.3310 - val_mean_squared_error: 12.3310\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.7894 - mean_squared_error: 8.7894 - val_loss: 12.1144 - val_mean_squared_error: 12.1144\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.6969 - mean_squared_error: 8.6969 - val_loss: 11.9839 - val_mean_squared_error: 11.9839\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.4719 - mean_squared_error: 8.4719 - val_loss: 12.4785 - val_mean_squared_error: 12.4785\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.2976 - mean_squared_error: 8.2976 - val_loss: 11.9219 - val_mean_squared_error: 11.9219\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.1785 - mean_squared_error: 8.1785 - val_loss: 13.3705 - val_mean_squared_error: 13.3705\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.2965 - mean_squared_error: 8.2965 - val_loss: 12.1214 - val_mean_squared_error: 12.1214\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.1158 - mean_squared_error: 8.1158 - val_loss: 12.3113 - val_mean_squared_error: 12.3113\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.9200 - mean_squared_error: 7.9200 - val_loss: 11.9109 - val_mean_squared_error: 11.9109\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.9313 - mean_squared_error: 7.9313 - val_loss: 12.2668 - val_mean_squared_error: 12.2668\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.5305 - mean_squared_error: 7.5305 - val_loss: 12.1253 - val_mean_squared_error: 12.1253\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.7766 - mean_squared_error: 7.7766 - val_loss: 12.1874 - val_mean_squared_error: 12.1874\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.8861 - mean_squared_error: 7.8861 - val_loss: 12.7776 - val_mean_squared_error: 12.7776\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.6116 - mean_squared_error: 7.6116 - val_loss: 12.0794 - val_mean_squared_error: 12.0794\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.4698 - mean_squared_error: 7.4698 - val_loss: 12.3241 - val_mean_squared_error: 12.3241\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.1573 - mean_squared_error: 7.1573 - val_loss: 12.1614 - val_mean_squared_error: 12.1614\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.1242 - mean_squared_error: 7.1242 - val_loss: 13.3512 - val_mean_squared_error: 13.3512\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.8647 - mean_squared_error: 7.8647 - val_loss: 13.2182 - val_mean_squared_error: 13.2182\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.2273 - mean_squared_error: 7.2273 - val_loss: 12.6288 - val_mean_squared_error: 12.6288\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.1636 - mean_squared_error: 7.1636 - val_loss: 12.2791 - val_mean_squared_error: 12.2791\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7997 - mean_squared_error: 6.7997 - val_loss: 12.6307 - val_mean_squared_error: 12.6307\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.8522 - mean_squared_error: 6.8522 - val_loss: 12.7989 - val_mean_squared_error: 12.7989\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.1369 - mean_squared_error: 7.1369 - val_loss: 15.1983 - val_mean_squared_error: 15.1983\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.9600 - mean_squared_error: 6.9600 - val_loss: 13.2110 - val_mean_squared_error: 13.2110\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.9032 - mean_squared_error: 7.9032 - val_loss: 14.2417 - val_mean_squared_error: 14.2417\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.7489 - mean_squared_error: 7.7489 - val_loss: 16.0128 - val_mean_squared_error: 16.0128\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.1215 - mean_squared_error: 8.1215 - val_loss: 13.4000 - val_mean_squared_error: 13.4000\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.5708 - mean_squared_error: 6.5708 - val_loss: 13.5590 - val_mean_squared_error: 13.5590\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.3062 - mean_squared_error: 6.3062 - val_loss: 13.1462 - val_mean_squared_error: 13.1462\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.1097 - mean_squared_error: 6.1097 - val_loss: 12.9970 - val_mean_squared_error: 12.9970\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.3311 - mean_squared_error: 6.3311 - val_loss: 13.1754 - val_mean_squared_error: 13.1754\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.1065 - mean_squared_error: 6.1065 - val_loss: 14.3690 - val_mean_squared_error: 14.3690\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.4740 - mean_squared_error: 6.4740 - val_loss: 14.0945 - val_mean_squared_error: 14.0945\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.3942 - mean_squared_error: 6.3942 - val_loss: 13.0714 - val_mean_squared_error: 13.0714\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.6902 - mean_squared_error: 6.6902 - val_loss: 14.2977 - val_mean_squared_error: 14.2977\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.5114 - mean_squared_error: 6.5114 - val_loss: 13.5968 - val_mean_squared_error: 13.5968\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.3432 - mean_squared_error: 6.3432 - val_loss: 15.6142 - val_mean_squared_error: 15.6142\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.7082 - mean_squared_error: 5.7082 - val_loss: 15.4289 - val_mean_squared_error: 15.4289\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.2595 - mean_squared_error: 6.2595 - val_loss: 14.1592 - val_mean_squared_error: 14.1592\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.2040 - mean_squared_error: 6.2040 - val_loss: 13.5938 - val_mean_squared_error: 13.5938\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.8595 - mean_squared_error: 5.8595 - val_loss: 14.7855 - val_mean_squared_error: 14.7855\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.7849 - mean_squared_error: 5.7849 - val_loss: 14.4951 - val_mean_squared_error: 14.4951\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.5461 - mean_squared_error: 5.5461 - val_loss: 14.2335 - val_mean_squared_error: 14.2335\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.7159 - mean_squared_error: 5.7159 - val_loss: 15.3160 - val_mean_squared_error: 15.3160\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.4536 - mean_squared_error: 5.4536 - val_loss: 14.1603 - val_mean_squared_error: 14.1603\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.2718 - mean_squared_error: 6.2718 - val_loss: 18.1661 - val_mean_squared_error: 18.1661\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.3574 - mean_squared_error: 7.3574 - val_loss: 13.7450 - val_mean_squared_error: 13.7450\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.5144 - mean_squared_error: 6.5144 - val_loss: 15.0226 - val_mean_squared_error: 15.0226\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.3789 - mean_squared_error: 5.3789 - val_loss: 14.2534 - val_mean_squared_error: 14.2534\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.9741 - mean_squared_error: 4.9741 - val_loss: 15.3674 - val_mean_squared_error: 15.3674\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7101 - mean_squared_error: 4.7101 - val_loss: 15.1869 - val_mean_squared_error: 15.1869\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.8336 - mean_squared_error: 4.8336 - val_loss: 14.2953 - val_mean_squared_error: 14.2953\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.9983 - mean_squared_error: 4.9983 - val_loss: 15.1877 - val_mean_squared_error: 15.1877\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1319 - mean_squared_error: 5.1319 - val_loss: 15.5616 - val_mean_squared_error: 15.5616\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1228 - mean_squared_error: 5.1228 - val_loss: 16.1623 - val_mean_squared_error: 16.1623\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1604 - mean_squared_error: 5.1604 - val_loss: 17.7148 - val_mean_squared_error: 17.7148\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.0284 - mean_squared_error: 6.0284 - val_loss: 15.2808 - val_mean_squared_error: 15.2808\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.5635 - mean_squared_error: 5.5635 - val_loss: 16.0500 - val_mean_squared_error: 16.0500\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7100 - mean_squared_error: 4.7100 - val_loss: 16.0288 - val_mean_squared_error: 16.0288\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.4981 - mean_squared_error: 4.4981 - val_loss: 14.8267 - val_mean_squared_error: 14.8267\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.4203 - mean_squared_error: 4.4203 - val_loss: 15.1171 - val_mean_squared_error: 15.1171\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.0408 - mean_squared_error: 5.0408 - val_loss: 16.3549 - val_mean_squared_error: 16.3549\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.1271 - mean_squared_error: 4.1271 - val_loss: 15.2545 - val_mean_squared_error: 15.2545\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2612 - mean_squared_error: 4.2612 - val_loss: 15.0491 - val_mean_squared_error: 15.0491\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8326 - mean_squared_error: 3.8326 - val_loss: 15.1359 - val_mean_squared_error: 15.1359\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.0011 - mean_squared_error: 4.0011 - val_loss: 14.7292 - val_mean_squared_error: 14.7292\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8708 - mean_squared_error: 3.8708 - val_loss: 15.9839 - val_mean_squared_error: 15.9839\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8037 - mean_squared_error: 3.8037 - val_loss: 16.3604 - val_mean_squared_error: 16.3604\n",
      "22/22 [==============================] - 0s 420us/step\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8582 - mean_squared_error: 23.4844\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8509 - mean_squared_error: 23.4510\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8362 - mean_squared_error: 23.3834\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.8187 - mean_squared_error: 23.3061\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7985 - mean_squared_error: 23.2161\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7736 - mean_squared_error: 23.1064\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7467 - mean_squared_error: 22.9872\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7169 - mean_squared_error: 22.8583\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6819 - mean_squared_error: 22.7045\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6431 - mean_squared_error: 22.5387\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5973 - mean_squared_error: 22.3423\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5399 - mean_squared_error: 22.0912\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4748 - mean_squared_error: 21.8205\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3956 - mean_squared_error: 21.4688\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2999 - mean_squared_error: 21.0794\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1883 - mean_squared_error: 20.6329\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0589 - mean_squared_error: 20.1107\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9141 - mean_squared_error: 19.5588\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7798 - mean_squared_error: 19.1181\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6862 - mean_squared_error: 18.9086\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6296 - mean_squared_error: 18.8194\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5878 - mean_squared_error: 18.7275\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5590 - mean_squared_error: 18.6055\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5368 - mean_squared_error: 18.4804\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5154 - mean_squared_error: 18.3462\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5067 - mean_squared_error: 18.3012\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4892 - mean_squared_error: 18.2105\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4751 - mean_squared_error: 18.1012\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4648 - mean_squared_error: 18.0173\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4547 - mean_squared_error: 17.9595\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4448 - mean_squared_error: 17.9094\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4347 - mean_squared_error: 17.8489\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4282 - mean_squared_error: 17.7827\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4150 - mean_squared_error: 17.6991\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4074 - mean_squared_error: 17.6523\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3977 - mean_squared_error: 17.5982\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3853 - mean_squared_error: 17.5475\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3721 - mean_squared_error: 17.4522\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3592 - mean_squared_error: 17.3481\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3503 - mean_squared_error: 17.3398\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3315 - mean_squared_error: 17.2028\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3167 - mean_squared_error: 17.1165\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3021 - mean_squared_error: 17.0591\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2830 - mean_squared_error: 16.9381\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2679 - mean_squared_error: 16.8361\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2450 - mean_squared_error: 16.7421\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2347 - mean_squared_error: 16.7478\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2103 - mean_squared_error: 16.5510\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1967 - mean_squared_error: 16.4200\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1761 - mean_squared_error: 16.3711\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1556 - mean_squared_error: 16.2457\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1346 - mean_squared_error: 16.0291\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1071 - mean_squared_error: 15.8892\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0915 - mean_squared_error: 15.8629\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0706 - mean_squared_error: 15.7550\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0406 - mean_squared_error: 15.5389\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0112 - mean_squared_error: 15.2959\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9914 - mean_squared_error: 15.2292\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9780 - mean_squared_error: 15.0509\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9474 - mean_squared_error: 14.9660\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9253 - mean_squared_error: 14.5758\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8953 - mean_squared_error: 14.5914\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8753 - mean_squared_error: 14.4815\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8530 - mean_squared_error: 14.2382\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8229 - mean_squared_error: 14.1363\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8123 - mean_squared_error: 14.0400\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7686 - mean_squared_error: 13.8088\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7448 - mean_squared_error: 13.5720\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7247 - mean_squared_error: 13.4276\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7321 - mean_squared_error: 13.6680\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6986 - mean_squared_error: 13.2162\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6841 - mean_squared_error: 13.1040\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7085 - mean_squared_error: 13.2059\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6717 - mean_squared_error: 13.2182\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6663 - mean_squared_error: 12.9068\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6619 - mean_squared_error: 13.0693\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5988 - mean_squared_error: 12.6042\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5279 - mean_squared_error: 12.1404\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5016 - mean_squared_error: 12.0224\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4768 - mean_squared_error: 11.9269\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4275 - mean_squared_error: 11.4536\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4061 - mean_squared_error: 11.3081\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3955 - mean_squared_error: 11.4549\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3760 - mean_squared_error: 11.0187\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3734 - mean_squared_error: 11.1548\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3351 - mean_squared_error: 10.8516\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3260 - mean_squared_error: 10.5802\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4340 - mean_squared_error: 11.2323\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3553 - mean_squared_error: 10.8029\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3450 - mean_squared_error: 10.7513\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3271 - mean_squared_error: 10.7881\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2462 - mean_squared_error: 10.0305\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2723 - mean_squared_error: 10.3720\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3576 - mean_squared_error: 10.2912\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3839 - mean_squared_error: 11.5207\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2968 - mean_squared_error: 10.0513\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2117 - mean_squared_error: 10.1022\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1410 - mean_squared_error: 9.2389\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1145 - mean_squared_error: 9.2706\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1148 - mean_squared_error: 9.1858\n",
      "10/10 [==============================] - 0s 454us/step\n"
     ]
    }
   ],
   "source": [
    "### R-Learner\n",
    "\n",
    "# estimate e_x\n",
    "r_learner_e_x = model_ex\n",
    "r_learner_mu_x.load_weights('model_ex')\n",
    "r_learner_e_x.fit(X_train,W_train,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, W_test),\n",
    "    callbacks=[callback] # include early stopping\n",
    ")\n",
    "\n",
    "# get e_x predictions\n",
    "r_probabilities = np.reshape(keras.activations.sigmoid(r_learner_e_x.predict(X_train)),len(X_train,))\n",
    "r_probas_1 = r_probabilities# probabilities of W=1\n",
    "r_probas_0 = 1 - r_probabilities # probabilities of W=0\n",
    "\n",
    "# estimate mu_x\n",
    "r_learner_mu_x = model_25\n",
    "r_learner_mu_x.load_weights('model_25')\n",
    "r_learner_mu_x.fit(X_train,Y_train,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "\n",
    "# compute r-pseudo-outcome and weights\n",
    "r_learner_pseudo_outcomes = (Y_train - np.reshape(r_learner_mu_x.predict(X_train),(len(X_train),))) / (W_train - r_probas_1)\n",
    "r_learner_weights = (W_train - r_probas_1)**2\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X, weight by (W-e(x))^2)\n",
    "r_learner_tau = model_25\n",
    "r_learner_tau.load_weights('model_25')\n",
    "r_learner_tau.fit(X_train,r_learner_pseudo_outcomes,\n",
    "    sample_weight=r_learner_weights,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=None,\n",
    "    callbacks=None # include early stopping\n",
    ")\n",
    "\n",
    "# predict tau\n",
    "r_tau_hats = r_learner_tau.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:41:09.302956Z",
     "start_time": "2023-06-06T19:41:05.169782Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "15.571879821571244"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.reshape(r_tau_hats,(len(X_test))) - tau_test)**2).mean() #14, with smoothing"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:41:10.327384Z",
     "start_time": "2023-06-06T19:41:10.251491Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DR-learner with NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
