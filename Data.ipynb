{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-14T19:39:13.524641Z",
     "start_time": "2023-06-14T19:39:12.868951Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import r packages if needed\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.packages as rpackages\n",
    "rpackages.importr(\"clusterGeneration\")\n",
    "rpackages.importr(\"mpower\")\n",
    "rpackages.importr(\"base\")\n",
    "rpackages.importr(\"utils\")\n",
    "cluster_generation = robjects.packages.importr(\"clusterGeneration\")\n",
    "mpower = robjects.packages.importr(\"mpower\")\n",
    "base = robjects.packages.importr(\"base\")\n",
    "utils = robjects.packages.importr(\"utils\")\n",
    "from numpy import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# SIMULATION SETUP: \"META-PARAMETERS\"\n",
    "\n",
    "sample_sizes = [1000,2000,5000,10000]\n",
    "test_sizes = [500,1000] # TODO: DECIDE\n",
    "runs = [10,30] # TODO: DECIDE HOW MANY RUNS (I.E. HOW MANY TIMES GENERATING ALL SETUPS AND RUNNING ALL META LEARNERS ON THEM)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T19:11:03.353934Z",
     "start_time": "2023-06-14T19:11:03.337606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# SIMULATION SETUP: SETUPS\n",
    "\n",
    "# i)            Balanced vs. Unbalanced\n",
    "# ii)           Confounding vs. No confounding\n",
    "\n",
    "# iii) A)       Treatment effect: --> Simple cate vs. Complex cate\n",
    "#                                    a) Complex cate --> Linear vs Non-linear cate\n",
    "\n",
    "# iii) B)       No effect: --> a) Global linear response vs. Piecewise linear response (globally non-linear)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T19:41:32.877438Z",
     "start_time": "2023-06-14T19:41:32.859010Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    " # Fully Synthetic Data Sets (Set up from Künzel et al.)\n",
    "\n",
    "# 1: Simulate the d-dimensional X.\n",
    "# 2: Create Potential Outcomes Y(1) and Y(0).\n",
    "# 3: Simulate Treatment Assignments trough W."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T19:41:33.221819Z",
     "start_time": "2023-06-14T19:41:33.212110Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "########################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T19:41:33.453220Z",
     "start_time": "2023-06-14T19:41:33.443511Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# 1: Simulate the d-dimensional X\n",
    "## TODO: PROBABLY HAVE TO DO THIS ON R: SINCE NO SET.SEED() POSSIBLE!\n",
    "\n",
    "# Setup parameters\n",
    "d = 25 # TODO: set dimension according to setup\n",
    "N = 1000 # TODO: set sample size according to setup\n",
    "\n",
    "# X Correlation matrix and mean\n",
    "mean = np.zeros(d) # TODO: set mean according to setup\n",
    "cov = np.array(mpower.cvine(d=d, alpha = 0.5, beta = 0.5)) # TODO: set cov according to setup\n",
    "\n",
    "# Simulate X\n",
    "X = random.multivariate_normal(mean=mean, cov=cov, size=N, check_valid='warn')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T19:47:05.308785Z",
     "start_time": "2023-06-14T19:47:05.154720Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "## EXAMPLE!\n",
    "\n",
    "# make 10 runs of dataset X\n",
    "# whole data generation procedure in this loop FOR EACH SETUP!!\n",
    "data = []\n",
    "d = 25 # TODO: set dimension according to setup\n",
    "N = 1000 # TODO: set sample size according to setup\n",
    "mean = np.zeros(d) # TODO: set mean according to setup\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    # 1 GENERATE FEATURES X\n",
    "    cov = np.array(mpower.cvine(d=d, alpha = 0.5, beta = 0.5)) # TODO: set cov according to setup\n",
    "    X = random.multivariate_normal(mean=mean, cov=cov, size=N, check_valid='warn')\n",
    "\n",
    "    # 2 GENERATE ERRORS E_0 & E_1\n",
    "    e_0 = random.normal(loc=0.0,scale=1.0,size=N)\n",
    "    e_1 = random.normal(loc=0.0,scale=1.0,size=N)\n",
    "\n",
    "    # 3 COMPUTE MU_0 & MU_1 (SIMPLE CATE, LINEAR, NO CONFOUNDING)\n",
    "    betas_0 = random.uniform(low=-5, high=5, size=d)\n",
    "    mu_0 = np.matmul(X,betas_0) + 5*X[:,0]\n",
    "    mu_1 = mu_0 + 8*X[:,1] # linear\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    # 4 CREATE POTENTIAL OUTCOMES Y_0 & Y_1\n",
    "    Y_0 = mu_0 + e_0\n",
    "    Y_1 = mu_1 + e_1\n",
    "\n",
    "    # 5 SET PROPENSITY SCORE E_X (CONSTANT, BALANCED)\n",
    "    e_x = 0.5\n",
    "\n",
    "    # 6 GENERATE TREATMENT ASSIGMENT W\n",
    "    W = random.binomial(size=N, n=1, p=e_x)\n",
    "\n",
    "    # 7 CREATE OBSERVED VARIABLES Y\n",
    "    Y = np.multiply(W,Y_1) + np.multiply(np.ones(N)-W,Y_0)\n",
    "\n",
    "    # 8 CREATE DATASET\n",
    "    dataset = np.concatenate((np.reshape(Y,(N,1)),X,np.reshape(W,(N,1)),np.reshape(tau,(N,1))), axis = 1)\n",
    "\n",
    "    # 9 APPEND RUN TO LIST\n",
    "    data.append(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T21:11:40.139912Z",
     "start_time": "2023-06-14T21:11:39.989588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1000\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(data)) # nr of datasets\n",
    "print(len(data[0])) # rows\n",
    "print(len(data[0][0])) # columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T21:24:30.556306Z",
     "start_time": "2023-06-14T21:24:30.438933Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.59608404, -0.29933383,  1.59713617, ...,  1.53098193,\n        -0.18772674, -2.3723548 ],\n       [ 1.1423447 ,  1.16866093,  1.11157359, ...,  1.16514249,\n         1.01378475, -0.8360739 ],\n       [-0.3193583 ,  0.62500306, -0.41479481, ..., -0.2886151 ,\n         0.9787185 ,  1.07939365],\n       ...,\n       [-0.36430581,  0.77298921, -0.18094212, ..., -0.28829545,\n         0.02839832,  1.14943272],\n       [-1.12286371, -1.27647492, -1.33435966, ..., -1.18377495,\n        -0.01305518,  0.22649884],\n       [-1.37387576, -1.79418329, -0.9688096 , ..., -1.37531261,\n        -2.34722033,  0.71357282]])"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check X\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T21:20:06.941556Z",
     "start_time": "2023-06-14T21:20:06.912722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check cov\n",
    "cov"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#######################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2: Create Potential Outcomes Y(1) and Y(0).\n",
    "\n",
    "# 2.1 Simulate errors, FIX\n",
    "e_0 = random.normal(loc=0.0,scale=1.0,size=N)\n",
    "e_1 = random.normal(loc=0.0,scale=1.0,size=N)\n",
    "\n",
    "# if needed take student_t distributed errors to see simulation with heavy-tailed errors\n",
    "\n",
    "# e_o = random.standard_t(df=1,size=N)\n",
    "# e_1 = random.standard_t(df=1,size=N)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#######################################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2.2 Create Response Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI1.1 simple cate - indicator  (no confounding)\n",
    "betas_0 = random.uniform(low=-5, high=5, size=d)\n",
    "mu_0 = np.matmul(X,betas_0) + 5*np.int8(X[:,0]>0.5)\n",
    "mu_1 = mu_0 + 8*np.int8(X[:,1]>0.1) # indicator\n",
    "tau = mu_1 - mu_0\n",
    "tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI1.2 simple cate - linear (no confounding)\n",
    "betas_0 = random.uniform(low=-5, high=5, size=d)\n",
    "mu_0 = np.matmul(X,betas_0) + 5*X[:,0]\n",
    "mu_1 = mu_0 + 8*X[:,1] # linear\n",
    "tau = mu_1 - mu_0\n",
    "tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI1.3 simple cate - quadratic (no confounding)\n",
    "betas_0 = random.uniform(low=-5, high=5, size=d)\n",
    "mu_0 = np.matmul(X,betas_0) + 5*(X[:,0]**2)\n",
    "mu_1 = mu_0 + 8*(X[:,1]**2) # quadratic\n",
    "tau = mu_1 - mu_0\n",
    "tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI2 complex linear cate  (in Künzel it is low=1, high=30)\n",
    "betas_0 = random.uniform(low=-15, high=15, size=d)\n",
    "betas_1 = random.uniform(low=-15, high=15, size=d)\n",
    "mu_0 = np.matmul(X,betas_0)\n",
    "mu_1 = np.matmul(X,betas_1)\n",
    "tau = mu_1 - mu_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###############################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def varsigma_funct(x):\n",
    "    return 2/(1+np.exp(-12*(x-1/2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI3 complex non-linear\n",
    "mu_0 = -1/2*varsigma_funct(x=X[:,0])*varsigma_funct(x=X[:,1])\n",
    "mu_1 = 1/2*varsigma_funct(x=X[:,0])*varsigma_funct(x=X[:,1])\n",
    "tau = mu_1 - mu_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI4 no treatment effect (global linear response)\n",
    "betas_noT = random.uniform(low=-15, high=15, size=d)\n",
    "mu_0 = np.matmul(X,betas_noT)\n",
    "mu_1 = mu_0\n",
    "tau = np.zeros(N)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###########################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI5 no treatment effect (piecewise linear response)\n",
    "betas = np.random.uniform(low=-15, high=15, size=d)\n",
    "\n",
    "betas_l = copy.copy(betas) # betas_lower\n",
    "betas_l[5:d] = 0\n",
    "\n",
    "betas_m = copy.copy(betas) #betas_middle\n",
    "betas_m[0:5] = 0\n",
    "betas_m[10:d] = 0\n",
    "\n",
    "betas_u = copy.copy(betas) #betas_upper\n",
    "betas_u[0:10] = 0\n",
    "betas_u[15:d] = 0\n",
    "\n",
    "def piecewise_linear_new(x):\n",
    "    condition_l = x[:, 19] < -0.4\n",
    "    condition_u = x[:, 19] > 0.4\n",
    "\n",
    "    array = np.zeros(N)\n",
    "    array[condition_l] = np.matmul(x[condition_l, :], betas_l)\n",
    "    array[~condition_l & ~condition_u] = np.matmul(x[~condition_l & ~condition_u, :], betas_m)\n",
    "    array[condition_u] = np.matmul(x[condition_u, :], betas_u)\n",
    "\n",
    "    return array\n",
    "\n",
    "mu_0 = piecewise_linear_new(X)\n",
    "\n",
    "mu_1 = mu_0\n",
    "\n",
    "tau = np.zeros(N)\n",
    "\n",
    "# TODO: CHECK IF RIGHT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##########################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI6.1 beta confounded, no treatment effect\n",
    "X = random.uniform(low=0, high=1, size=(N,d)) # ACHTUNG: nöd wiederhole!\n",
    "mu_0 = 2*X[:,0] - 1\n",
    "mu_1 = mu_0\n",
    "tau = np.zeros(N)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI6.2 beta confounded, simple cate (indicator)\n",
    "X = random.uniform(low=0, high=1, size=(N,d))\n",
    "mu_0 = 2*X[:,0] - 1\n",
    "mu_1 = mu_0 + 2*np.int8(X[:,1]>0.4)\n",
    "tau = mu_1 - mu_0\n",
    "tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI6.3 beta confounded, simple cate (linear)\n",
    "X = random.uniform(low=0, high=1, size=(N,d))\n",
    "mu_0 = 2*X[:,0] - 1\n",
    "mu_1 = mu_0 + 2*X[:,1]\n",
    "tau = mu_1 - mu_0\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI6.4 beta confounded, simple cate (quadratic)\n",
    "X = random.uniform(low=0, high=1, size=(N,d))\n",
    "mu_0 = 2*X[:,0] - 1\n",
    "mu_1 = mu_0 + 2*(X[:,1]**2)\n",
    "tau = mu_1 - mu_0\n",
    "tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI7.1 beta confounded, complex cate (linear)\n",
    "betas = random.uniform(low=-15, high=15, size=d)\n",
    "\n",
    "mu_0 = 2*X[:,0] - 1\n",
    "mu_1 = mu_0 + np.matmul(X,betas)\n",
    "tau = mu_1 - mu_0\n",
    "\n",
    "# TODO: CHECK WHETHER THIS SETUP MAKES SENSE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SI7.2 beta confounded, complex cate (non-linear)\n",
    "mu_0 = 2*X[:,0] - 1\n",
    "mu_1 = mu_0 + 1/2*varsigma_funct(x=X[:,0])*varsigma_funct(x=X[:,1])\n",
    "\n",
    "# TODO: CHECK WHETER THIS SETUP MAKES SENSE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: check relationship between mu_0 & mu_1 and see whether this makes sense\n",
    "check_values_0 = 2*X[:,0] - 1\n",
    "check_values_1 = mu_0 + 1/2*varsigma_funct(x=X[:,0])*varsigma_funct(x=X[:,1])\n",
    "check_values_2 = mu_0 + np.matmul(X,betas)\n",
    "\n",
    "plt.plot(check_values_0, check_values_1, 'bo')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###################################\n",
    "# 2.3 Creat Potential Outcomes, FIX\n",
    "Y_0 = mu_0 + e_0\n",
    "Y_1 = mu_1 + e_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# quick check Y_0\n",
    "Y_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quick Check Y_1\n",
    "Y_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###################################\n",
    "# 3.1 Propensity score setups # TODO: change for setup\n",
    "\n",
    "# i) constant, balanced\n",
    "e_x = 0.5\n",
    "\n",
    "# ii) constant, unbalanced\n",
    "e_x = 0.01"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iii) beta confounded (balanced)\n",
    "X = random.uniform(low=0, high=1, size=(N,d))\n",
    "beta_dist = stats.beta(a=2, b=4) # set beta distribution\n",
    "beta_values = beta_dist.pdf(X[:,0]) # calculate pdf values for x1\n",
    "e_x = 1/4*(1+beta_values)\n",
    "\n",
    "pd.DataFrame(e_x).describe() # summary stats of e_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if balanced\n",
    "W = random.binomial(size=N, n=1, p=e_x)\n",
    "pd.DataFrame(W).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#####################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iv) beta confounded (unbalanced)\n",
    "X = random.uniform(low=0, high=1, size=(N,d))\n",
    "beta_dist = stats.beta(a=1, b=10) # set beta distribution\n",
    "beta_values = beta_dist.pdf(X[:,0]) # calculate pdf values for x1\n",
    "e_x = 1/100*(1+beta_values)\n",
    "\n",
    "pd.DataFrame(e_x).describe() # summary stats of e_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if unbalanced and how much\n",
    "W = random.binomial(size=N, n=1, p=e_x)\n",
    "pd.DataFrame(W).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##########################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###################################"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3.2 Simulate Treatment Assignments trough W\n",
    "\n",
    "# Simulate Treatment Assignment, FIX\n",
    "W = random.binomial(size=N, n=1, p=e_x)\n",
    "\n",
    "# Create Observed Outcome, FIX\n",
    "ones = np.ones(N)\n",
    "Y = np.multiply(W,Y_1) + np.multiply(ones-W,Y_0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(e_x).describe() # summary stats of e_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check out observed outcomes\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(Y).describe() # summary stats of Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = np.concatenate((np.reshape(Y,(N,1)),X,np.reshape(W,(N,1)),np.reshape(tau,(N,1))), axis = 1)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.apppend(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IHDP datset from Fredjo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 100 realisations of IHDP train set (672 units)\n",
    "ihdp_train = load('/Users/arberimbibaj/Downloads/ihdp_npci_1-100.train.npz')\n",
    "files_train = ihdp_train.files\n",
    "files_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 100 realisations of IHDP test set (72 units)\n",
    "ihdp_test = load('/Users/arberimbibaj/Downloads/ihdp_npci_1-100.test.npz')\n",
    "files_test = ihdp_test.files\n",
    "files_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for example\n",
    "ihdp_train['mu1']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cate per realisation\n",
    "ihdp_train['mu1'] - ihdp_train['mu0']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
