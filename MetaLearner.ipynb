{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.saving import load_model\n",
    "\n",
    "# from abc import ABC, abstractmethod\n",
    "\n",
    "from default_parameters import *\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make GPU available for keras\n",
    "# https://medium.com/mlearning-ai/install-tensorflow-on-mac-m1-m2-with-gpu-support-c404c6cfb580"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set float64 as standard\n",
    "tf.keras.backend.set_floatx('float64')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# Why 0 GPUs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set global seed\n",
    "tf.keras.utils.set_random_seed(8953)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/arberimbibaj/dataset_example_indicatorCATE.csv', header=None, index_col=[0])\n",
    "data = data.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "d = len(data[0, :]) - 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train test split\n",
    "random.shuffle(data)\n",
    "training, test = data[:700, :], data[700:, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# slice dataset by treatment status\n",
    "training_control = training[training[:, 26] == 0]\n",
    "training_treatment = training[training[:, 26] == 1]\n",
    "\n",
    "# slice test set by treatment status\n",
    "test_control = test[test[:, 26] == 0]\n",
    "test_treatment = test[test[:, 26] == 1]\n",
    "\n",
    "# Y_train by treatment status\n",
    "Y_train_control = training_control[:, 0]\n",
    "Y_train_treatment = training_treatment[:, 0]\n",
    "\n",
    "# Y_test by treatment status\n",
    "Y_test_control = test_control[:, 0]\n",
    "Y_test_treatment = test_treatment[:, 0]\n",
    "\n",
    "# X_train by treatment status\n",
    "X_train_control = training_control[:, 1:26]\n",
    "X_train_treatment = training_treatment[:, 1:26]\n",
    "\n",
    "# X_test by treatment status\n",
    "X_test_control = test_control[:, 1:26]\n",
    "X_test_treatment = test_treatment[:, 1:26]\n",
    "\n",
    "# X and Y test\n",
    "X_test = test[:, 1:26]\n",
    "Y_test = test[:, 0]\n",
    "\n",
    "# X_train and Y_train (no split by treatment status)\n",
    "X_train = training[:, 1:26]\n",
    "Y_train = training[:, 0]\n",
    "\n",
    "# W_train and W_test\n",
    "W_train = training[:, 26]\n",
    "W_test = test[:, 26]\n",
    "\n",
    "# tau_test\n",
    "tau_test = test[:, 27]\n",
    "tau_test_control = test_control[:, 27]\n",
    "tau_test_treatment = test_treatment[:, 27]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set training and test features for the S-Learner (it views W as no different from other X's)\n",
    "X_W_train = training[:, 1:27]\n",
    "X_W_test = test[:, 1:27]\n",
    "X_test_0 = np.concatenate((test[:, 1:26], np.zeros((300, 1))), axis=1)\n",
    "X_test_1 = np.concatenate((test[:, 1:26], np.ones((300, 1))), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=7, max_features=0.3)\n",
    "rf.fit(X_train, W_train)\n",
    "probs = rf.predict_proba(X_train)\n",
    "probs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs = pd.DataFrame(probs[:, 0])\n",
    "probs.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1 = clone_nn_regression(nn_sequential)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1.fit(X_train, Y_train, epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = clone_nn_regression(nn_sequential)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2.fit(X_train, Y_train, epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model3 = clone_nn_regression(nn_sequential)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model3.fit(X_train, Y_train, epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "T-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# T-Learner (example with Random Forest)\n",
    "\n",
    "# mu_0\n",
    "t_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "t_learner_mu0.fit(X_train_control, Y_train_control)\n",
    "t_mu_0_hat = t_learner_mu0.predict(X_test)\n",
    "\n",
    "# mu_1\n",
    "t_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "t_learner_mu1.fit(X_train_treatment, Y_train_treatment)\n",
    "t_mu_1_hat = t_learner_mu1.predict(X_test)\n",
    "# Prediction = mu_1 - mu_0\n",
    "t_tau_hat = t_mu_1_hat - t_mu_0_hat\n",
    "t_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((t_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "S-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### S-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S-learner (example with Random Forest)\n",
    "\n",
    "# mu_x\n",
    "s_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "s_learner.fit(X_W_train, Y_train)\n",
    "\n",
    "# mu_0_hat\n",
    "s_mu_0_hat = s_learner.predict(X_test_0)\n",
    "\n",
    "# mu_1_hat\n",
    "s_mu_1_hat = s_learner.predict(X_test_1)\n",
    "\n",
    "# tau_hat\n",
    "s_tau_hat = s_mu_1_hat - s_mu_0_hat\n",
    "s_tau_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((s_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### X-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_learner_mu0.fit(X_train_control, Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_learner_mu1.fit(X_train_treatment, Y_train_treatment)\n",
    "\n",
    "# compute imputed treatment effect D_0 and D_1\n",
    "# d_0\n",
    "imputed_0 = x_learner_mu1.predict(X_train_control) - Y_train_control\n",
    "\n",
    "# d_1\n",
    "imputed_1 = Y_train_treatment - x_learner_mu0.predict(X_train_treatment)\n",
    "\n",
    "# regress imputed on X\n",
    "# tau_hat_0\n",
    "x_tau_0_hat = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_tau_0_hat.fit(X_train_control, imputed_0)\n",
    "\n",
    "# tau_hat_1\n",
    "x_tau_1_hat = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_tau_1_hat.fit(X_train_treatment, imputed_1)\n",
    "\n",
    "# estimate e_x to use as g_x\n",
    "g_x_hat = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "g_x_hat.fit(X_train, W_train)\n",
    "probabilities = g_x_hat.predict_proba(X_test)\n",
    "probas_1 = probabilities[:, 1]\n",
    "probas_0 = probabilities[:, 0]\n",
    "\n",
    "# final estimator of tau\n",
    "x_tau_hat = probas_1 * x_tau_0_hat.predict(X_test) + probas_0 * x_tau_1_hat.predict(X_test)\n",
    "x_tau_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### See g_x hat\n",
    "g_x_hat.predict_proba(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error (much lower here!)\n",
    "((x_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind = np.random.choice(len(X_train), int(len(X_train) / 2), replace=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lol = np.array((1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n",
    "lol"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_ind = np.random.choice(10, int(10 / 2), replace=False)\n",
    "train_ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind = np.zeros(len(X_train), dtype=bool)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind[train_ind] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train[ind]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "~ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lol[ind]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lol[~ind]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "~ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train[ind]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "R-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### R-Learner\n",
    "# split for cross-fitting\n",
    "index = np.zeros(len(X_train), dtype=bool)\n",
    "train_ind = np.random.choice(len(X_train), int(len(X_train) / 2), replace=False)\n",
    "index[train_ind] = 1\n",
    "\n",
    "# estimate e_x\n",
    "r_learner_e_x_1 = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "r_learner_e_x_2 = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "r_learner_e_x_1.fit(X_train[index], W_train[index])\n",
    "r_learner_e_x_2.fit(X_train[~index], W_train[~index])\n",
    "\n",
    "# get e_x predictions\n",
    "r_probas_1 = np.zeros(len(X_train), )\n",
    "r_probas_1[index] = r_learner_e_x_2.predict_proba(X_train[index])[:, 1]\n",
    "r_probas_1[~index] = r_learner_e_x_1.predict_proba(X_train[~index])[:, 1]\n",
    "\n",
    "#r_probas_0 = r_probas[:, 0]  # probabilities of W=0\n",
    "#r_probas_1 = r_probas[:, 1]  # probabilities of W=1\n",
    "\n",
    "# estimate mu_x\n",
    "r_learner_mu_x = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "r_learner_mu_x.fit(X_train, Y_train)\n",
    "\n",
    "# compute r-pseudo-outcome and weights\n",
    "r_learner_pseudo_outcomes = (Y_train - r_learner_mu_x.predict(X_train)) / (W_train - r_probas_1)\n",
    "r_learner_weights = (W_train - r_probas_1) ** 2\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X, weight by (W-e(x))^2)\n",
    "r_learner_tau = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "r_learner_tau.fit(X_train, r_learner_pseudo_outcomes, sample_weight=r_learner_weights)\n",
    "\n",
    "# predict tau\n",
    "r_tau_hats = r_learner_tau.predict(X_test)\n",
    "r_tau_hats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_probas[index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_learner_e_x.predict_proba(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((r_tau_hats - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DR-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### DR-Learner\n",
    "\n",
    "# TODO: APPLY CROSS-FITTING?\n",
    "# estimate e_x\n",
    "dr_learner_e_x = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "dr_learner_e_x.fit(X_train, W_train)\n",
    "\n",
    "dr_probas = dr_learner_e_x.predict_proba(X_train)\n",
    "dr_probas_0 = dr_probas[:, 0]  # probabilities of W=0\n",
    "dr_probas_1 = dr_probas[:, 1]  # probabilities of W=1\n",
    "\n",
    "# estimate mu_0\n",
    "dr_learner_mu_0 = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "dr_learner_mu_0.fit(X_train_control, Y_train_control)\n",
    "\n",
    "# estimate mu_1\n",
    "dr_learner_mu_1 = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "dr_learner_mu_1.fit(X_train_treatment, Y_train_treatment)\n",
    "\n",
    "# DR-pseudo-outcomes\n",
    "mu_w = W_train * dr_learner_mu_1.predict(X_train) + (1 - W_train) * dr_learner_mu_0.predict(\n",
    "    X_train)  # this is mu_w for each observation, i.e. mu_1 for units in the treatment groups, and mu_0 for units in the control group\n",
    "dr_pseudo_outcomes = (W_train - dr_probas_1) / (dr_probas_1 * dr_probas_0) * (Y_train - mu_w) + dr_learner_mu_1.predict(\n",
    "    X_train) - dr_learner_mu_0.predict(X_train)\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X) # TODO: USE \"Test Set\" for this estimation\n",
    "dr_learner_tau_hat = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "dr_learner_tau_hat.fit(X_train, dr_pseudo_outcomes)\n",
    "\n",
    "# predict tau\n",
    "dr_tau_hat = dr_learner_tau_hat.predict(X_test)\n",
    "dr_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((dr_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RA-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### RA-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_learner_mu0.fit(X_train_control, Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_learner_mu1.fit(X_train_treatment, Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "ra_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "ra_learner_e_x.fit(X_train, W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "ra_pseudo_outcome = W_train * (Y_train - ra_learner_mu0.predict(X_train)) + (1 - W_train) * (\n",
    "        ra_learner_mu1.predict(X_train) - Y_train)\n",
    "\n",
    "# tau_hat\n",
    "ra_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_tau_hat_learner.fit(X_train, ra_pseudo_outcome)\n",
    "ra_tau_hat = ra_tau_hat_learner.predict(X_test)\n",
    "ra_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((ra_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PW-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ACHTUNG: TRIED TO INCLUDE CROSS-FITTING!\n",
    "### PW-Learner\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu0_1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu0_2 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu0_1.fit(X_train_control, Y_train_control)\n",
    "pw_learner_mu0_2.fit(X_train_control, Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu1_1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu1_2 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu1_1.fit(X_train_treatment, Y_train_treatment)\n",
    "pw_learner_mu1_2.fit(X_train_treatment, Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "# split for cross-fitting\n",
    "index = np.zeros(len(X_train), dtype=bool)\n",
    "train_ind = np.random.choice(len(X_train), int(len(X_train) / 2), replace=False)\n",
    "index[train_ind] = 1\n",
    "\n",
    "pw_learner_e_x_1 = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "pw_learner_e_x_2 = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "pw_learner_e_x_1.fit(X_train[index], W_train[index])\n",
    "pw_learner_e_x_2.fit(X_train[~index], W_train[~index])\n",
    "\n",
    "pw_probas_1 = np.zeros(len(X_train), )\n",
    "pw_probas_1[index] = pw_learner_e_x_2.predict_proba(X_train[index])[:, 1]\n",
    "pw_probas_1[~index] = pw_learner_e_x_1.predict_proba(X_train[~index])[:, 1]\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "pw_pseudo_outcome = (W_train / pw_probas_1 - (1 - W_train) / (1 - pw_probas_1)) * Y_train\n",
    "\n",
    "# tau_hat\n",
    "pw_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_tau_hat_learner.fit(X_train, pw_pseudo_outcome)\n",
    "pw_tau_hat = pw_tau_hat_learner.predict(X_test)\n",
    "pw_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((pw_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "U-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### U-Learner\n",
    "# estimate e_x\n",
    "u_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "u_learner_e_x.fit(X_train, W_train)\n",
    "\n",
    "# estimate mu_x\n",
    "u_learner_mu_x = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "u_learner_mu_x.fit(X_train, Y_train)\n",
    "\n",
    "# compute residuals\n",
    "u_learner_residuals = (Y_train - u_learner_mu_x.predict(X_train)) / (\n",
    "        W_train - u_learner_e_x.predict_proba(X_train)[:, 1])\n",
    "\n",
    "# tau_hat - regress residuals on X\n",
    "u_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "u_tau_hat_learner.fit(X_train, u_learner_residuals)\n",
    "\n",
    "u_tau_hats = u_tau_hat_learner.predict(X_test)\n",
    "u_tau_hats\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((u_tau_hats - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(u_learner_e_x.predict_proba(X_train)[:, 1]).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u_learner_residuals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lasso (or L1-loss for logistic regression)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess for lasso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "poly_train = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "X_poly_train = poly_train.fit_transform(X_train)\n",
    "poly_test = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "X_poly_test = poly_test.fit_transform(X_test)\n",
    "X_poly_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute polynomial features for treatment and control groups in training set\n",
    "poly_train_treatment = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "X_poly_train_treatment = poly_train_treatment.fit_transform(X_train_treatment)\n",
    "poly_train_control = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "X_poly_train_control = poly_train_treatment.fit_transform(X_train_control)\n",
    "poly_test = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "X_poly_test = poly_test.fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compute polynomial features for treatment and control groups in training set\n",
    "xw_poly_train = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_W_poly_train = poly_train_treatment.fit_transform(X_W_train)\n",
    "\n",
    "xw_poly_test_0 = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test_0 = xw_poly_test_0.fit_transform(X_test_0)\n",
    "\n",
    "xw_poly_test_1 = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test_1 = xw_poly_test_0.fit_transform(X_test_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "T-learner (Lasso)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# T-Learner (example with Lasso)\n",
    "\n",
    "# mu_0\n",
    "t_learner_mu0 = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "t_learner_mu0.fit(X_poly_train_control, Y_train_control)\n",
    "t_mu_0_hat = t_learner_mu0.predict(X_poly_test)\n",
    "\n",
    "# mu_1\n",
    "t_learner_mu1 = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "t_learner_mu1.fit(X_poly_train_treatment, Y_train_treatment)\n",
    "t_mu_1_hat = t_learner_mu1.predict(X_poly_test)\n",
    "\n",
    "# Prediction = mu_1 - mu_0\n",
    "t_tau_hat = t_mu_1_hat - t_mu_0_hat\n",
    "t_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((t_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "S-learner (Lasso)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S-learner (example with Random Forest)\n",
    "tic = time.perf_counter()\n",
    "# mu_x\n",
    "s_learner = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "s_learner.fit(X_W_poly_train, Y_train)\n",
    "\n",
    "# mu_0_hat\n",
    "s_mu_0_hat = s_learner.predict(X_poly_test_0)\n",
    "\n",
    "# mu_1_hat\n",
    "s_mu_1_hat = s_learner.predict(X_poly_test_1)\n",
    "\n",
    "# tau_hat\n",
    "s_tau_hat = s_mu_1_hat - s_mu_0_hat\n",
    "toc = time.perf_counter()\n",
    "print(f'Time for computation: {toc - tic}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((s_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X-learner (Lasso (or l1-penalty))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### X-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_learner_mu0.fit(X_poly_train_control, Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_learner_mu1.fit(X_poly_train_treatment, Y_train_treatment)\n",
    "\n",
    "# compute imputed treatment effect D_0 and D_1\n",
    "# d_0\n",
    "imputed_0 = x_learner_mu1.predict(X_poly_train_control) - Y_train_control\n",
    "\n",
    "# d_1\n",
    "imputed_1 = Y_train_treatment - x_learner_mu0.predict(X_poly_train_treatment)\n",
    "\n",
    "# regress imputed on X\n",
    "# tau_hat_0\n",
    "x_tau_0_hat = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_tau_0_hat.fit(X_poly_train_control, imputed_0)\n",
    "\n",
    "# tau_hat_1\n",
    "x_tau_1_hat = LassoCV(cv=10, tol=1, random_state=0)\n",
    "x_tau_1_hat.fit(X_poly_train_treatment, imputed_1)\n",
    "\n",
    "# estimate e_x to use as g_x\n",
    "g_x_hat = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "g_x_hat.fit(X_poly_train, W_train)\n",
    "probabilities = g_x_hat.predict_proba(X_poly_test)\n",
    "probas_1 = probabilities[:, 1]\n",
    "probas_0 = probabilities[:, 0]\n",
    "\n",
    "# final estimator of tau\n",
    "x_tau_hat = probas_1 * x_tau_0_hat.predict(X_poly_test) + probas_0 * x_tau_1_hat.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc - tic}')  # 127 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((x_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "R-learner (Lasso (or l1-penalty))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### R-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# estimate e_x\n",
    "r_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "r_learner_e_x.fit(X_poly_train, W_train)\n",
    "\n",
    "# get e_x predictions\n",
    "r_probas = r_learner_e_x.predict_proba(X_poly_train)\n",
    "r_probas_0 = r_probas[:, 0]  # probabilities of W=0\n",
    "r_probas_1 = r_probas[:, 1]  # probabilities of W=1\n",
    "\n",
    "# estimate mu_x\n",
    "r_learner_mu_x = LassoCV(cv=10, tol=1, random_state=0)\n",
    "r_learner_mu_x.fit(X_poly_train, Y_train)\n",
    "\n",
    "# compute r-pseudo-outcome and weights\n",
    "r_learner_pseudo_outcomes = (Y_train - r_learner_mu_x.predict(X_poly_train)) / (W_train - r_probas_1)\n",
    "r_learner_weights = (W_train - r_probas_1) ** 2\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X, weight by (W-e(x))^2)\n",
    "r_learner_tau = LassoCV(cv=10, tol=1, random_state=0)\n",
    "r_learner_tau.fit(X_poly_train, r_learner_pseudo_outcomes, sample_weight=r_learner_weights)\n",
    "\n",
    "# predict tau\n",
    "r_tau_hats = r_learner_tau.predict(X_poly_test)\n",
    "r_tau_hats\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc - tic} seconds')  # 98 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((r_tau_hats - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DR-learner (Lasso (l1-penalty))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### DR-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# TODO: APPLY CROSS-FITTING?\n",
    "# estimate e_x\n",
    "dr_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "dr_learner_e_x.fit(X_poly_train, W_train)\n",
    "\n",
    "dr_probas = dr_learner_e_x.predict_proba(X_poly_train)\n",
    "dr_probas_0 = dr_probas[:, 0]  # probabilities of W=0\n",
    "dr_probas_1 = dr_probas[:, 1]  # probabilities of W=1\n",
    "\n",
    "# estimate mu_0\n",
    "dr_learner_mu_0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "dr_learner_mu_0.fit(X_poly_train_control, Y_train_control)\n",
    "\n",
    "# estimate mu_1\n",
    "dr_learner_mu_1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "dr_learner_mu_1.fit(X_poly_train_treatment, Y_train_treatment)\n",
    "\n",
    "# DR-pseudo-outcomes\n",
    "mu_w = W_train * dr_learner_mu_1.predict(X_poly_train) + (1 - W_train) * dr_learner_mu_0.predict(\n",
    "    X_poly_train)  # this is mu_w for each observation, i.e. mu_1 for units in the treatment groups, and mu_0 for units in the control group\n",
    "dr_pseudo_outcomes = (W_train - dr_probas_1) / (dr_probas_1 * dr_probas_0) * (Y_train - mu_w) + dr_learner_mu_1.predict(\n",
    "    X_poly_train) - dr_learner_mu_0.predict(X_poly_train)\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X) # TODO: USE \"Test Set\" for this estimation\n",
    "dr_learner_tau_hat = LassoCV(cv=10, tol=1, random_state=0)\n",
    "dr_learner_tau_hat.fit(X_poly_train, dr_pseudo_outcomes)\n",
    "\n",
    "# predict tau\n",
    "dr_tau_hat = dr_learner_tau_hat.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time needed for computation: {toc - tic} seconds')  # 104 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((dr_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RA-learner (Lasso)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### RA-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "ra_learner_mu0.fit(X_poly_train_control, Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "ra_learner_mu1.fit(X_poly_train_treatment, Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "ra_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "ra_learner_e_x.fit(X_poly_train, W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "ra_pseudo_outcome = W_train * (Y_train - ra_learner_mu0.predict(X_poly_train)) + (1 - W_train) * (\n",
    "        ra_learner_mu1.predict(X_poly_train) - Y_train)\n",
    "\n",
    "# tau_hat\n",
    "ra_tau_hat_learner = LassoCV(cv=10, tol=1, random_state=0)\n",
    "ra_tau_hat_learner.fit(X_poly_train, ra_pseudo_outcome)\n",
    "ra_tau_hat = ra_tau_hat_learner.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc - tic} seconds.')  # 121 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((ra_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PW-learner (Lasso)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### PW-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu0 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "pw_learner_mu0.fit(X_poly_train_control, Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu1 = LassoCV(cv=10, tol=1, random_state=0)\n",
    "pw_learner_mu1.fit(X_poly_train_treatment, Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "pw_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "pw_learner_e_x.fit(X_poly_train, W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "pw_pseudo_outcome = (W_train / pw_learner_e_x.predict_proba(X_poly_train)[:, 1] - (1 - W_train) / (\n",
    "    pw_learner_e_x.predict_proba(X_poly_train)[:, 0])) * Y_train\n",
    "\n",
    "# tau_hat\n",
    "pw_tau_hat_learner = LassoCV(cv=10, tol=1, random_state=0)\n",
    "pw_tau_hat_learner.fit(X_poly_train, pw_pseudo_outcome)\n",
    "pw_tau_hat = pw_tau_hat_learner.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc - tic} seconds.')  # 117 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((pw_tau_hat - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "U-learner (Lasso)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### U-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# estimate e_x\n",
    "u_learner_e_x = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "u_learner_e_x.fit(X_poly_train, W_train)\n",
    "\n",
    "# estimate mu_x\n",
    "u_learner_mu_x = LassoCV(cv=10, tol=1, random_state=0)\n",
    "u_learner_mu_x.fit(X_poly_train, Y_train)\n",
    "\n",
    "# compute residuals\n",
    "u_learner_residuals = (Y_train - u_learner_mu_x.predict(X_poly_train)) / (\n",
    "        W_train - u_learner_e_x.predict_proba(X_poly_train)[:, 1])\n",
    "\n",
    "# tau_hat - regress residuals on X\n",
    "u_tau_hat_learner = LassoCV(cv=10, tol=1, random_state=0)\n",
    "u_tau_hat_learner.fit(X_poly_train, u_learner_residuals)\n",
    "\n",
    "u_tau_hats = u_tau_hat_learner.predict(X_poly_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc - tic} seconds.')  # 98 seconds\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((u_tau_hats - tau_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "T-Learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# T-Learner (example with Random Forest)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# mu_0\n",
    "t_learner_mu0 = load_model('model_25')\n",
    "print('Training mu0')\n",
    "t_learner_mu0.fit(X_train_control, Y_train_control,\n",
    "                  batch_size=100,\n",
    "                  epochs=100,\n",
    "                  validation_data=(X_test, Y_test),\n",
    "                  callbacks=None  # include early stopping\n",
    "                  )\n",
    "t_mu_0_hat = t_learner_mu0.predict(X_test)\n",
    "\n",
    "# mu_1\n",
    "t_learner_mu1 = load_model('model_25')\n",
    "print('Training mu1')\n",
    "t_learner_mu1.fit(X_train_treatment, Y_train_treatment,\n",
    "                  batch_size=100,\n",
    "                  epochs=100,\n",
    "                  validation_data=(X_test, Y_test),\n",
    "                  callbacks=None  # include early stopping\n",
    "                  )\n",
    "t_mu_1_hat = t_learner_mu1.predict(X_test)\n",
    "\n",
    "# Prediction = mu_1 - mu_0\n",
    "t_tau_hat = t_mu_1_hat - t_mu_0_hat\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time for computation: {toc - tic} seconds.')  # 3 seconds\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(t_tau_hat, (300,)) - tau_test) ** 2).mean()  # 3.18"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "S-learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S-learner (example with Random Forest)\n",
    "\n",
    "# mu_x\n",
    "s_learner = load_model('model_26')\n",
    "s_learner.fit(X_W_train, Y_train,\n",
    "              batch_size=100,\n",
    "              epochs=100,\n",
    "              validation_data=(X_W_test, Y_test),\n",
    "              callbacks=None  # include early stopping\n",
    "              )\n",
    "\n",
    "# mu_0_hat\n",
    "s_mu_0_hat = s_learner.predict(X_test_0)\n",
    "\n",
    "# mu_1_hat\n",
    "s_mu_1_hat = s_learner.predict(X_test_1)\n",
    "\n",
    "# tau_hat\n",
    "s_tau_hat = s_mu_1_hat - s_mu_0_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(s_tau_hat, (300,)) - tau_test) ** 2).mean()  # 1.98"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X-learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### X-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu0 = load_model('model_25')\n",
    "x_learner_mu0.fit(X_train_control, Y_train_control,\n",
    "                  batch_size=100,\n",
    "                  epochs=100,\n",
    "                  validation_data=(X_test_control, Y_test_control),\n",
    "                  callbacks=None  # include early stopping\n",
    "                  )\n",
    "\n",
    "# d_1\n",
    "imputed_1 = Y_train_treatment - np.reshape(x_learner_mu0.predict(X_train_treatment), (len(Y_train_treatment),))\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu1 = load_model('model_25')\n",
    "x_learner_mu1.fit(X_train_treatment, Y_train_treatment,\n",
    "                  batch_size=100,\n",
    "                  epochs=100,\n",
    "                  validation_data=(X_test_treatment, Y_test_treatment),\n",
    "                  callbacks=None  # include early stopping\n",
    "                  )\n",
    "\n",
    "# d_0\n",
    "imputed_0 = np.reshape(x_learner_mu1.predict(X_train_control), (len(Y_train_control),)) - Y_train_control\n",
    "\n",
    "# regress imputed on X\n",
    "\n",
    "# tau_hat_1\n",
    "x_tau_1_hat = load_model('model_25')\n",
    "x_tau_1_hat.fit(X_train_treatment, imputed_1,\n",
    "                batch_size=100,\n",
    "                epochs=100,\n",
    "                validation_data=(X_test_treatment, tau_test_treatment),\n",
    "                callbacks=None  # include early stopping\n",
    "                )\n",
    "\n",
    "x_tau_1_hat_predicts = np.reshape(x_tau_1_hat.predict(X_test), (len(X_test),))\n",
    "\n",
    "# tau_hat_0\n",
    "x_tau_0_hat = load_model('model_25')\n",
    "x_tau_0_hat.fit(X_train_control, imputed_0,\n",
    "                batch_size=100,\n",
    "                epochs=100,\n",
    "                validation_data=(X_test_control, tau_test_control),\n",
    "                callbacks=None  # include early stopping\n",
    "                )\n",
    "\n",
    "x_tau_0_hat_predicts = np.reshape(x_tau_0_hat.predict(X_test), (len(X_test),))\n",
    "\n",
    "# estimate e_x to use as g_x\n",
    "g_x_hat = load_model('model_ex')\n",
    "g_x_hat.fit(X_train, W_train,\n",
    "            batch_size=100,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, W_test),\n",
    "            callbacks=None  # include early stopping\n",
    "            )\n",
    "x_probabilities = g_x_hat.predict(X_test)\n",
    "x_probs_1 = np.reshape(keras.activations.sigmoid(x_probabilities), (len(x_probabilities, )))\n",
    "x_probs_0 = 1 - x_probs_1\n",
    "\n",
    "# final estimator of tau\n",
    "x_tau_hat = x_probs_1 * x_tau_0_hat_predicts + x_probs_0 * x_tau_1_hat_predicts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(x_tau_hat, (300,)) - tau_test) ** 2).mean()  # 3.1614 with smoothing of 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "R-learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### R-Learner\n",
    "\n",
    "# estimate e_x\n",
    "r_learner_e_x = load_model('model_ex')\n",
    "r_learner_e_x.fit(X_train, W_train,\n",
    "                  batch_size=100,\n",
    "                  epochs=100,\n",
    "                  validation_data=(X_test, W_test),\n",
    "                  callbacks=None  # include early stopping\n",
    "                  )\n",
    "\n",
    "# get e_x predictions\n",
    "r_probabilities = np.reshape(keras.activations.sigmoid(r_learner_e_x.predict(X_train)), len(X_train, ))\n",
    "r_probas_1 = r_probabilities  # probabilities of W=1\n",
    "r_probas_0 = 1 - r_probabilities  # probabilities of W=0\n",
    "\n",
    "# estimate mu_x\n",
    "r_learner_mu_x = load_model('model_25')\n",
    "r_learner_mu_x.fit(X_train, Y_train,\n",
    "                   batch_size=100,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_test, Y_test),\n",
    "                   callbacks=None  # include early stopping\n",
    "                   )\n",
    "\n",
    "# compute r-pseudo-outcome and weights\n",
    "r_learner_pseudo_outcomes = (Y_train - np.reshape(r_learner_mu_x.predict(X_train), (len(X_train),))) / (\n",
    "        W_train - r_probas_1)\n",
    "r_learner_weights = (W_train - r_probas_1) ** 2\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X, weight by (W-e(x))^2)\n",
    "r_learner_tau = load_model('model_25')\n",
    "r_learner_tau.fit(X_train, r_learner_pseudo_outcomes,\n",
    "                  sample_weight=r_learner_weights,\n",
    "                  batch_size=100,\n",
    "                  epochs=100,\n",
    "                  validation_data=None,\n",
    "                  callbacks=None  # include early stopping\n",
    "                  )\n",
    "\n",
    "# predict tau\n",
    "r_tau_hats = r_learner_tau.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(r_tau_hats, (len(X_test))) - tau_test) ** 2).mean()  #47.81"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DR-learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### DR-Learner\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "# TODO: APPLY CROSS-FITTING?\n",
    "# estimate e_x\n",
    "dr_learner_e_x = load_model('model_ex')\n",
    "dr_learner_e_x.fit(X_train, W_train,\n",
    "                   batch_size=100,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_test, W_test),\n",
    "                   callbacks=None  # include early stopping\n",
    "                   )\n",
    "\n",
    "dr_probabilities = np.reshape(keras.activations.sigmoid(dr_learner_e_x.predict(X_train)), len(X_train, ))\n",
    "dr_probas_0 = 1 - dr_probabilities  # probabilities of W=0\n",
    "dr_probas_1 = dr_probabilities  # probabilities of W=1\n",
    "\n",
    "# estimate mu_0\n",
    "dr_learner_mu_0 = load_model('model_25')\n",
    "dr_learner_mu_0.fit(X_train_control, Y_train_control,\n",
    "                    batch_size=100,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_test_control, Y_test_control),\n",
    "                    callbacks=None  # include early stopping\n",
    "                    )\n",
    "\n",
    "dr_learner_mu_0_predictions = dr_learner_mu_0.predict(X_train)\n",
    "\n",
    "# estimate mu_1\n",
    "dr_learner_mu_1 = load_model('model_25')\n",
    "dr_learner_mu_1.fit(X_train_treatment, Y_train_treatment,\n",
    "                    batch_size=100,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_test_treatment, Y_test_treatment),\n",
    "                    callbacks=None  # include early stopping\n",
    "                    )\n",
    "\n",
    "dr_learner_mu_1_predictions = dr_learner_mu_1.predict(X_train)\n",
    "\n",
    "# DR-pseudo-outcomes\n",
    "mu_w = W_train * dr_learner_mu_1_predictions + (\n",
    "        1 - W_train) * dr_learner_mu_0_predictions  # this is mu_w for each observation, i.e. mu_1 for units in the treatment groups, and mu_0 for units in the control group\n",
    "dr_pseudo_outcomes = (W_train - dr_probas_1) / (dr_probas_1 * dr_probas_0) * (\n",
    "        Y_train - mu_w) + dr_learner_mu_1_predictions - dr_learner_mu_0_predictions\n",
    "\n",
    "# estimate tau (regress pseudo-outcomes on X) # TODO: USE \"Test Set\" for this estimation\n",
    "dr_learner_tau_hat = load_model('model_25')\n",
    "dr_learner_tau_hat.fit(X_train, dr_pseudo_outcomes,\n",
    "                       batch_size=100,\n",
    "                       epochs=100,\n",
    "                       validation_data=None,\n",
    "                       callbacks=None  # include early stopping\n",
    "                       )\n",
    "\n",
    "# predict tau\n",
    "dr_tau_hat = dr_learner_tau_hat.predict(X_test)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f'Time needed for computation: {toc - tic} seconds')  # 104 seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(dr_tau_hat, (len(tau_test),)) - tau_test) ** 2).mean()  # 8.3514"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RA-learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### RA-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu0 = load_model('model_25')\n",
    "ra_learner_mu0.fit(X_train_control, Y_train_control,\n",
    "                   batch_size=100,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_test_control, Y_test_control),\n",
    "                   callbacks=None  # include early stopping\n",
    "                   )\n",
    "\n",
    "# get hats\n",
    "ra_learner_mu0_predictions = np.reshape(ra_learner_mu0.predict(X_train), (len(X_train),))\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu1 = load_model('model_25')\n",
    "ra_learner_mu1.fit(X_train_treatment, Y_train_treatment,\n",
    "                   batch_size=100,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_test_treatment, Y_test_treatment),\n",
    "                   callbacks=None  # include early stopping\n",
    "                   )\n",
    "\n",
    "# get hats\n",
    "ra_learner_mu1_predictions = np.reshape(ra_learner_mu1.predict(X_train), (len(X_train),))\n",
    "\n",
    "# e_x TODO: IS IT NEEDED?\n",
    "\"\"\"ra_learner_e_x = load_model('model_ex')\n",
    "ra_learner_e_x.fit(X_train,W_train,\n",
    "    batch_size=100,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, W_test),\n",
    "    callbacks=[callback] # include early stopping\n",
    ")\"\"\"\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "ra_pseudo_outcome = W_train * (Y_train - ra_learner_mu0_predictions) + (1 - W_train) * (\n",
    "        ra_learner_mu1_predictions - Y_train)\n",
    "\n",
    "# tau_hat\n",
    "ra_tau_hat_learner = load_model('model_25')\n",
    "ra_tau_hat_learner.fit(X_train, ra_pseudo_outcome,\n",
    "                       batch_size=100,\n",
    "                       epochs=100,\n",
    "                       validation_data=None,\n",
    "                       callbacks=None  # include early stopping\n",
    "                       )\n",
    "\n",
    "ra_tau_hat = ra_tau_hat_learner.predict(X_test)\n",
    "ra_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(ra_tau_hat, (len(tau_test),)) - tau_test) ** 2).mean()  # 3.397"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PW-learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### PW-Learner\n",
    "\n",
    "# e_x\n",
    "pw_learner_e_x = load_model('model_ex')\n",
    "pw_learner_e_x.fit(X_train, W_train,\n",
    "                   batch_size=100,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_test, W_test),\n",
    "                   callbacks=None  # include early stopping\n",
    "                   )\n",
    "\n",
    "pw_probabilities = np.reshape(keras.activations.sigmoid(pw_learner_e_x.predict(X_train)), len(X_train, ))\n",
    "pw_probs_1 = pw_probabilities\n",
    "pw_probs_0 = 1 - pw_probabilities\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "pw_pseudo_outcome = (W_train / pw_probs_1 - (1 - W_train) / pw_probs_0) * Y_train\n",
    "\n",
    "# tau_hat\n",
    "pw_tau_hat_learner = load_model('model_25')\n",
    "pw_tau_hat_learner.fit(X_train, pw_pseudo_outcome,\n",
    "                       batch_size=100,\n",
    "                       epochs=100,\n",
    "                       validation_data=None,\n",
    "                       callbacks=None  # include early stopping\n",
    "                       )\n",
    "pw_tau_hat = pw_tau_hat_learner.predict(X_test)\n",
    "pw_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(pw_tau_hat, (len(tau_test),)) - tau_test) ** 2).mean()  # 271.842 TODO: CHECK IF IT REALLY IS CORRECT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# see why so bad\n",
    "pw_probabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "U-learner (NN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### U-Learner\n",
    "# estimate e_x\n",
    "\n",
    "u_learner_e_x = load_model('model_ex')\n",
    "u_learner_e_x.fit(X_train, W_train,\n",
    "                  batch_size=100,\n",
    "                  epochs=1000,\n",
    "                  validation_split=0.3,\n",
    "                  callbacks=callback  # include early stopping\n",
    "                  )\n",
    "\n",
    "u_probs_1 = np.reshape(keras.activations.sigmoid(u_learner_e_x.predict(X_train)), (len(X_train),))\n",
    "\n",
    "# estimate mu_x\n",
    "u_learner_mu_x = load_model('model_25')\n",
    "u_learner_mu_x.fit(X_train, Y_train,\n",
    "                   batch_size=100,\n",
    "                   epochs=100,\n",
    "                   validation_data=None,\n",
    "                   callbacks=None\n",
    "                   )\n",
    "\n",
    "u_learner_mu_x_predictions = np.reshape(u_learner_mu_x.predict(X_train), (len(X_train),))\n",
    "# compute residuals\n",
    "u_learner_residuals = (Y_train - u_learner_mu_x_predictions) / (W_train - u_probs_1)\n",
    "\n",
    "# tau_hat - regress residuals on X\n",
    "u_tau_hat_learner = load_model('model_25')\n",
    "u_tau_hat_learner.fit(X_train, u_learner_residuals,\n",
    "                      batch_size=100,\n",
    "                      epochs=1000,\n",
    "                      callbacks=callback,\n",
    "                      validation_split=0.3\n",
    "                      )\n",
    "\n",
    "u_tau_hats = u_tau_hat_learner.predict(X_test)\n",
    "u_tau_hats\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((np.reshape(u_tau_hats, (len(tau_test),)) - tau_test) ** 2).mean()  # 51.102 TODO: CHECK IF IT REALLY IS CORRECT!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u_learner_residuals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(u_probs_1).describe()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Metalearner:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class T Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TLearner:  # TODO: comment what is what.\n",
    "    def __init__(self, method):  # TODO: or maybe not give base_learners but method, i.e. : 'lasso', 'rf' or 'nn'\n",
    "        self.method = method\n",
    "\n",
    "        if method == 'rf':\n",
    "            self.mu0_model = RandomForestRegressor(n_estimators=1000, max_depth=99, random_state=0, max_features=0.66)\n",
    "            self.mu1_model = RandomForestRegressor(n_estimators=1000, max_depth=99, random_state=0, max_features=0.66)\n",
    "        elif method == 'lasso':\n",
    "            self.mu0_model = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "            self.mu1_model = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "            self.poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "        elif method == 'nn':\n",
    "            self.mu0_model = load_model('model_25')\n",
    "            self.mu1_model = load_model('model_25')\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified')\n",
    "\n",
    "    def fit(self,\n",
    "            x, y, w):  # TODO: training process\n",
    "        if self.method == 'rf':\n",
    "            # 1: train mu_0\n",
    "            print(\"Fitting random forest for mu_0\")\n",
    "            self.mu0_model.fit(x[w == 0], y[w == 0])\n",
    "\n",
    "            # 2: train mu_1\n",
    "            print(\"Fitting random forest for mu_1\")\n",
    "            self.mu1_model.fit(x[w == 1], y[w == 1])\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            # make polynomial features\n",
    "            x_poly_train = self.poly.fit_transform(x)\n",
    "\n",
    "            # 1: train mu_0\n",
    "            print(\"Fitting lasso for mu_0\")\n",
    "            self.mu0_model.fit(x_poly_train[w == 0], y[w == 0])\n",
    "\n",
    "            # 2: train mu_1\n",
    "            print(\"Fitting lasso for mu_1\")\n",
    "            self.mu1_model.fit(x_poly_train[w == 1], y[w == 1])\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "            w = tf.convert_to_tensor(w)\n",
    "\n",
    "            # 1: train mu_0\n",
    "            print(\"Training neural network for mu_0\")\n",
    "            self.mu0_model.fit(x[w == 0], y[w == 0],\n",
    "                               batch_size=100,\n",
    "                               epochs=10000,\n",
    "                               callbacks=callback,\n",
    "                               validation_split=0.3,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "            # 2: train mu_1\n",
    "            print(\"Training neural network for mu_1\")\n",
    "            self.mu1_model.fit(x[w == 1], y[w == 1],\n",
    "                               batch_size=100,\n",
    "                               epochs=10000,\n",
    "                               callbacks=callback,  # include early stopping\n",
    "                               validation_split=0.3,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in fit')\n",
    "\n",
    "    def predict(self,\n",
    "                x):  # TODO:\n",
    "        if self.method == 'rf':\n",
    "            # 1: calculate hats of mu_1 & mu_0\n",
    "            mu0_hats = self.mu0_model.predict(x)\n",
    "            mu1_hats = self.mu1_model.predict(x)\n",
    "            predictions = mu1_hats - mu0_hats\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            # make polynomial features\n",
    "            x_poly_test = self.poly.fit_transform(x)\n",
    "\n",
    "            # 1: calculate hats of mu_1 & mu_0\n",
    "            mu0_hats = self.mu0_model.predict(x_poly_test)\n",
    "            mu1_hats = self.mu1_model.predict(x_poly_test)\n",
    "            predictions = mu1_hats - mu0_hats\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            mu0_hats = self.mu0_model(x)\n",
    "            mu1_hats = self.mu1_model(x)\n",
    "            predictions = np.reshape(mu1_hats - mu0_hats, (len(x),))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_nn = TLearner(method='nn')\n",
    "t_nn.fit(X_train, Y_train, W_train)\n",
    "predictions = t_nn.predict(X_test)\n",
    "((predictions - tau_test) ** 2).mean()\n",
    "# rf: 10.091322530886687 / 7.359776707186481 (max_features=0.66)\n",
    "# lasso: 5.583461099392904\n",
    "# nn: 3.1867804239471273"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stratified = StratifiedKFold(n_splits=CF_FOLDS, shuffle=True, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for (train_index, test_index) in stratified.split(X_train, W_train):\n",
    "    temp_model = load_model('model_25')\n",
    "    print('New Fold')\n",
    "    temp_model.fit(X_train[train_index], Y_train[train_index], epochs=30)\n",
    "    print(temp_model.predict(X_train[test_index]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class S Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SLearner:  # TODO: comment what is what.\n",
    "    def __init__(self, method):  # TODO: or maybe not give base_learners but method, i.e. : 'lasso', 'rf' or 'nn'\n",
    "        self.method = method\n",
    "\n",
    "        if method == 'rf':\n",
    "            self.mux_model = RandomForestRegressor(n_estimators=2000, max_depth=100, random_state=0, max_features=0.66)\n",
    "        elif method == 'lasso':\n",
    "            self.mux_model = LassoCV(cv=10, tol=1e-2, random_state=0)\n",
    "            self.poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "        elif method == 'nn':\n",
    "            self.mux_model = load_model('model_26')\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified')\n",
    "\n",
    "    def fit(self,\n",
    "            x, y, w):  # TODO: training process\n",
    "        x_w = np.concatenate((x, np.reshape(w, (len(w), 1))), axis=1)\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            # 1: train mu_x\n",
    "            print(\"Fitting random forest for mu_x\")\n",
    "            self.mux_model.fit(x_w, y)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            # make polynomial features\n",
    "            x_poly_train = self.poly.fit_transform(x_w)\n",
    "\n",
    "            # 1: train mu_x\n",
    "            print(\"Fitting lasso for mu_x\")\n",
    "            self.mux_model.fit(x_poly_train, y)\n",
    "\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            x_w = tf.convert_to_tensor(x_w)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "\n",
    "            # 1: train mu_x\n",
    "            print(\"Training neural network for mu_x\")\n",
    "            self.mux_model.fit(x_w, y,\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=None,  # include early stopping\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in fit')\n",
    "\n",
    "    def predict(self,\n",
    "                x):  # TODO:\n",
    "        x_0 = np.concatenate((x, np.zeros((len(x), 1))), axis=1)\n",
    "        x_1 = np.concatenate((x, np.ones((len(x), 1))), axis=1)\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            # 1: calculate hats of mu_x with X and W=1 or W=0\n",
    "            mu0_hats = self.mux_model.predict(x_0)\n",
    "            mu1_hats = self.mux_model.predict(x_1)\n",
    "            predictions = mu1_hats - mu0_hats\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            # make polynomial features\n",
    "            x_poly_0 = self.poly.fit_transform(x_0)\n",
    "            x_poly_1 = self.poly.fit_transform(x_1)\n",
    "\n",
    "            # 1: calculate hats of mu_x with X and W=1 or W=0\n",
    "            mu0_hats = self.mux_model.predict(x_poly_0)\n",
    "            mu1_hats = self.mux_model.predict(x_poly_1)\n",
    "            predictions = mu1_hats - mu0_hats\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            x_0 = tf.convert_to_tensor(x_0)\n",
    "            x_1 = tf.convert_to_tensor(x_1)\n",
    "            # 1: calculate hats of mu_x with X and W=1 or W=0\n",
    "            mu0_hats = self.mux_model(x_0)\n",
    "            mu1_hats = self.mux_model(x_1)\n",
    "            predictions = np.reshape(mu1_hats - mu0_hats, (len(x),))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s_nn = SLearner('nn')\n",
    "s_nn.fit(X_train, Y_train, W_train)\n",
    "predictions = s_nn.predict(X_test)\n",
    "((predictions - tau_test) ** 2).mean()\n",
    "# rf: 18.134009488483855\n",
    "# lasso: 5.559126710289806\n",
    "# nn: 1.987529792077956"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class X Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class XLearner:  # TODO: comment what is what.\n",
    "    def __init__(self, method):  # TODO: or maybe not give base_learners but method, i.e. : 'lasso', 'rf' or 'nn'\n",
    "        self.method = method\n",
    "\n",
    "        if method == 'rf':\n",
    "            self.mu0_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.mu1_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.ex_model = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "            self.tau0_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.tau1_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "\n",
    "        elif method == 'lasso':\n",
    "            self.mu0_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.mu1_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.ex_model = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "            self.tau0_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.tau1_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "\n",
    "        elif method == 'nn':\n",
    "            self.mu0_model = load_model('model_25')\n",
    "            self.mu1_model = load_model('model_25')\n",
    "            self.ex_model = load_model('model_ex')\n",
    "            self.tau0_model = load_model('model_25')\n",
    "            self.tau1_model = load_model('model_25')\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified')\n",
    "\n",
    "    def fit(self,\n",
    "            x, y, w):  # TODO: training process\n",
    "        if self.method == 'rf':\n",
    "            # 1: train mu_0 and get imputed_1\n",
    "            print(\"Fitting random forest for mu_0\")\n",
    "            self.mu0_model.fit(x[w == 0], y[w == 0])\n",
    "            imputed_1 = y[w == 1] - self.mu0_model.predict(x[w == 1])\n",
    "\n",
    "            # 2: train mu_1 and get imputed_0\n",
    "            print(\"Fitting random forest for mu_1\")\n",
    "            self.mu1_model.fit(x[w == 1], y[w == 1])\n",
    "            imputed_0 = self.mu1_model.predict(x[w == 0]) - y[w == 0]\n",
    "\n",
    "            # 3: train tau_0\n",
    "            print(\"Fitting random forest for tau_0\")\n",
    "            self.tau0_model.fit(x[w == 0], imputed_0)\n",
    "\n",
    "            # 4: train tau_1\n",
    "            print(\"Fitting random forest for tau_1\")\n",
    "            self.tau1_model.fit(x[w == 1], imputed_1)\n",
    "\n",
    "            # 5: train e_x\n",
    "            print(\"Fitting random forest for e_x\")\n",
    "            self.ex_model.fit(x, w)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            # make polynomial features\n",
    "            x_poly_train = self.poly.fit_transform(x)\n",
    "\n",
    "            # 1: train mu_0 and get imputed_1\n",
    "            print(\"Fitting lasso for mu_0\")\n",
    "            self.mu0_model.fit(x_poly_train[w == 0], y[w == 0])\n",
    "            imputed_1 = y[w == 1] - self.mu0_model.predict(x_poly_train[w == 1])\n",
    "\n",
    "            # 2: train mu_1 and get imputed_0\n",
    "            print(\"Fitting lasso for mu_1\")\n",
    "            self.mu1_model.fit(x_poly_train[w == 1], y[w == 1])\n",
    "            imputed_0 = self.mu1_model.predict(x_poly_train[w == 0]) - y[w == 0]\n",
    "\n",
    "            # 3: train tau_0\n",
    "            print(\"Fitting random forest for tau_0\")\n",
    "            self.tau0_model.fit(x_poly_train[w == 0], imputed_0)\n",
    "\n",
    "            # 4: train tau_1\n",
    "            print(\"Fitting random forest for tau_1\")\n",
    "            self.tau1_model.fit(x_poly_train[w == 1], imputed_1)\n",
    "\n",
    "            # 5: train e_x\n",
    "            print(\"Fitting random forest for e_x\")\n",
    "            self.ex_model.fit(x_poly_train, w)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "            w = tf.convert_to_tensor(w)\n",
    "\n",
    "            imputed_0 = np.empty(len(x), )\n",
    "            imputed_1 = np.empty(len(x), )\n",
    "\n",
    "            # 1: train mu_0\n",
    "            print(\"Training neural network for mu_0\")\n",
    "            for train_index, test_index in stratified.split(x, w):\n",
    "                index = np.zeros(len(x), dtype=bool)\n",
    "                index[test_index] = 1\n",
    "\n",
    "                temp_model = load_model('model_25')\n",
    "\n",
    "                x_train = x[~index]\n",
    "                x_test = x[index]\n",
    "                w_train = w[~index]\n",
    "                w_test = w[index]\n",
    "                y_train = y[~index]\n",
    "                y_test = y[index]\n",
    "\n",
    "                temp_model.fit(x_train[w_train == 0], y_train[w_train == 0],\n",
    "                               epochs=100,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "                imputed_1[index][w_test == 1] = y_test[w_test == 1] - np.reshape(temp_model(x_test[w_test == 1]),\n",
    "                                                                                 (len(x_test[w_test == 1]),))\n",
    "\n",
    "            imputed_1 = tf.convert_to_tensor(imputed_1)\n",
    "\n",
    "            \"\"\"self.mu0_model.fit(x[w == 0], y[w == 0],\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=None,  # include early stopping\n",
    "                               verbose=0\n",
    "                               )\n",
    "            imputed_1 = y[w == 1] - np.reshape(self.mu0_model(x[w == 1]), (len(x[w == 1]),))\"\"\"\n",
    "\n",
    "            # 2: train mu_1\n",
    "            print(\"Training neural network for mu_1\")\n",
    "\n",
    "            for train_index, test_index in stratified.split(x, w):\n",
    "                index = np.zeros(len(x), dtype=bool)\n",
    "                index[test_index] = 1\n",
    "\n",
    "                temp_model = load_model('model_25')\n",
    "                x_train = x[~index]\n",
    "                x_test = x[index]\n",
    "                w_train = w[~index]\n",
    "                w_test = w[index]\n",
    "                y_train = y[~index]\n",
    "\n",
    "                temp_model.fit(x_train[w_train == 1], y_train[w_train == 1],\n",
    "                               epochs=100,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "                imputed_0[index][w_test == 0] = np.array(temp_model(x_test[w_test == 0])).squeeze() - y_test[\n",
    "                    w_test == 0]\n",
    "\n",
    "            imputed_0 = tf.convert_to_tensor(imputed_0)\n",
    "\n",
    "            \"\"\"self.mu1_model.fit(x[w == 1], y[w == 1],\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=None,  # include early stopping\n",
    "                               verbose=0\n",
    "                               )\n",
    "            imputed_0 = np.reshape(self.mu1_model(x[w == 0]), (len(x[w == 0]),)) - y[w == 0]\"\"\"\n",
    "\n",
    "            # 3: train tau_0\n",
    "            print(\"Fitting random forest for tau_0\")\n",
    "            self.tau0_model.fit(x[w == 0], imputed_0[w == 0],\n",
    "                                batch_size=100,\n",
    "                                epochs=100,\n",
    "                                callbacks=None,  # include early stopping\n",
    "                                verbose=0\n",
    "                                )\n",
    "\n",
    "            # 4: train tau_1\n",
    "            print(\"Fitting random forest for tau_1\")\n",
    "            self.tau1_model.fit(x[w == 1], imputed_1[w == 1],\n",
    "                                batch_size=100,\n",
    "                                epochs=100,\n",
    "                                callbacks=None,  # include early stopping\n",
    "                                verbose=0\n",
    "                                )\n",
    "\n",
    "            # 5: train e_x\n",
    "            print(\"Fitting random forest for e_x\")\n",
    "            self.ex_model.fit(x, w,\n",
    "                              batch_size=100,\n",
    "                              epochs=100,\n",
    "                              callbacks=None,  # include early stopping\n",
    "                              verbose=0\n",
    "                              )\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in fit')\n",
    "\n",
    "    def predict(self,\n",
    "                x):  # TODO:\n",
    "        if self.method == 'rf':\n",
    "            # 1: calculate hats of tau_0 and tau_1\n",
    "            tau_0_hats = self.tau0_model.predict(x)\n",
    "            tau_1_hats = self.tau1_model.predict(x)\n",
    "            # 2: probabilities\n",
    "            probs = self.ex_model.predict_proba(x)[:, 1]\n",
    "            # 3: final predictions\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            # make polynomial features\n",
    "            x_poly_test = self.poly.fit_transform(x)\n",
    "\n",
    "            # 1: calculate hats of tau_0 and tau_1\n",
    "            tau_0_hats = self.tau0_model.predict(x_poly_test)\n",
    "            tau_1_hats = self.tau1_model.predict(x_poly_test)\n",
    "            probs = self.ex_model.predict_proba(x_poly_test)[:, 1]\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            # 1: calculate hats of tau_0 and tau_1\n",
    "            tau_0_hats = np.reshape(self.tau0_model(x), (len(x),))\n",
    "            tau_1_hats = np.reshape(self.tau1_model(x), (len(x),))\n",
    "            # 2: probabilities\n",
    "            logit = self.ex_model(x)\n",
    "            probs = np.reshape(keras.activations.sigmoid(logit), (len(logit, )))\n",
    "            # 3: final predictions\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "\n",
    "        predictions = probs * tau_0_hats + (1 - probs) * tau_1_hats\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_rf = XLearner('nn')\n",
    "x_rf.fit(X_train, Y_train, W_train)\n",
    "predictions = x_rf.predict(X_test)\n",
    "((predictions - tau_test) ** 2).mean()\n",
    "# rf: # 3.1369636408859614 --> same (good)\n",
    "# lasso: # nn: 7.667219448077926 --> same (good)\n",
    "# nn: 3.161416602361538 --> same (good)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imputed_1 = np.empty(len(X_train), )\n",
    "\n",
    "for train_index, test_index in stratified.split(X_train, W_train):\n",
    "    index = np.zeros(len(X_train), dtype=bool)\n",
    "    index[test_index] = 1\n",
    "\n",
    "    temp_model = load_model('model_25')\n",
    "\n",
    "    x_train = X_train[~index]\n",
    "    x_test = X_train[index]\n",
    "    w_train = W_train[~index]\n",
    "    w_test = W_train[index]\n",
    "    y_train = Y_train[~index]\n",
    "    y_test = Y_train[index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_model(x_test[w_test == 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test[w_test == 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = np.zeros(len(X_train), dtype=bool)\n",
    "for train_index, test_index in stratified.split(X_train, W_train):\n",
    "    index[test_index] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stratified = StratifiedKFold(n_splits=CF_FOLDS, shuffle=True, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for (train_index, test_index) in stratified.split(X_train, W_train):\n",
    "    temp_model = load_model('model_25')\n",
    "    print('New Fold')\n",
    "    temp_model.fit(X_train[train_index], Y_train[train_index], epochs=30)\n",
    "    print(temp_model.predict(X_train[test_index]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.experimental.numpy.empty(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# R-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RLearner:\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "\n",
    "        if method == 'rf':\n",
    "            self.mux_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.ex_model = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "            self.tau_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "\n",
    "        elif method == 'lasso':\n",
    "            self.mux_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.ex_model = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "            self.tau_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "\n",
    "        elif method == 'nn':\n",
    "            self.mux_model = load_model('model_25')\n",
    "            self.ex_model = load_model('model_ex')\n",
    "            self.tau_model = load_model('model_25')\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified or typo')\n",
    "\n",
    "    def fit(self, x, y, w):\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            # 1: fit mu_x\n",
    "            print('Fitting random forest for mu_x')\n",
    "            self.mux_model.fit(x, y)\n",
    "\n",
    "            print('Fitting random forest for e_x')\n",
    "            # 2: fit ex\n",
    "            self.ex_model.fit(x, w)\n",
    "\n",
    "            # 3: calculate pseudo_outcomes & weights\n",
    "            probs = self.ex_model.predict_proba(x)[:, 1]\n",
    "            pseudo_outcomes = (y - self.mux_model.predict(x)) / (w - probs)\n",
    "            weights = (w - probs) ** 2\n",
    "\n",
    "            print('Fitting random forest for tau_x')\n",
    "            # 4: fit tau\n",
    "            self.tau_model.fit(x, pseudo_outcomes, sample_weight=weights)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_train = self.poly.fit_transform(x)\n",
    "\n",
    "            # 1: fit mu_x\n",
    "            print('Fitting lasso for mu_x')\n",
    "            self.mux_model.fit(x_poly_train, y)\n",
    "\n",
    "            # 2: fit ex\n",
    "            print('Fitting lasso for e_x')\n",
    "            self.ex_model.fit(x_poly_train, w)\n",
    "\n",
    "            # 3: calculate pseudo_outcomes & weights\n",
    "            probs = self.ex_model.predict_proba(x_poly_train)[:, 1]\n",
    "            pseudo_outcomes = (y - self.mux_model.predict(x_poly_train)) / (w - probs)\n",
    "            weights = (w - probs) ** 2\n",
    "\n",
    "            # 4: fit tau\n",
    "            print('Fitting lasso for tau_x')\n",
    "            self.tau_model.fit(x_poly_train, pseudo_outcomes, sample_weight=weights)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "            w = tf.convert_to_tensor(w)\n",
    "\n",
    "            # 1: fit mu_x\n",
    "            print('Training NN for mu_x')\n",
    "            self.mux_model.fit(x, y,\n",
    "                               batch_size=100,\n",
    "                               epochs=400,\n",
    "                               callbacks=callback,\n",
    "                               validation_split=0.3,\n",
    "                               verbose=0\n",
    "                               )\n",
    "            # 2: fit ex\n",
    "            print('Training NN for e_x')\n",
    "            self.ex_model.fit(x, w,\n",
    "                              batch_size=100,\n",
    "                              epochs=400,\n",
    "                              callbacks=callback,\n",
    "                              validation_split=0.3,\n",
    "                              verbose=0\n",
    "                              )\n",
    "\n",
    "            # 3: calculate pseudo_outcomes & weights\n",
    "            probs = np.reshape(keras.activations.sigmoid(self.ex_model(x)), len(x, ))\n",
    "            pseudo_outcomes = (y - np.reshape(self.mux_model(x), (len(x),))) / (w - probs)\n",
    "            weights = (w - probs) ** 2\n",
    "\n",
    "            # 4: fit tau\n",
    "            print('Training NN for tau_x')\n",
    "            self.tau_model.fit(x, pseudo_outcomes,\n",
    "                               sample_weight=weights,\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=callback,\n",
    "                               validation_split=0.3,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in fit')\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            predictions = self.tau_model.predict(x)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_test = self.poly.fit_transform(x)\n",
    "            predictions = self.tau_model.predict(x_poly_test)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            predictions = np.reshape(self.tau_model(x), (len(x),))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_rf = RLearner('nn')\n",
    "r_rf.fit(X_train, Y_train, W_train)\n",
    "predictions = r_rf.predict(X_test)\n",
    "((predictions - tau_test) ** 2).mean()\n",
    "# rf: 17.722925118749608\n",
    "# lasso: 5.50038865455844\n",
    "# nn: 47.81939839016621"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class DR-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DRLearner:\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "        if method == 'rf':\n",
    "            self.mu0_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.mu1_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.ex_model = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.tau_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "\n",
    "        elif method == 'lasso':\n",
    "            self.mu0_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.mu1_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.ex_model = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "            self.tau_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "\n",
    "        elif method == 'nn':\n",
    "            self.mu0_model = load_model('model_25')\n",
    "            self.mu1_model = load_model('model_25')\n",
    "            self.ex_model = load_model('model_ex')\n",
    "            self.tau_model = load_model('model_25')\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified or typo')\n",
    "\n",
    "    def fit(self, x, y, w):\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            # 1: fit mu_0\n",
    "            print('Fitting random forest for mu_0')\n",
    "            self.mu0_model.fit(x[w == 0], y[w == 0])\n",
    "\n",
    "            # 2: fit mu_1\n",
    "            print('Fitting random forest for mu_1')\n",
    "            self.mu1_model.fit(x[w == 1], y[w == 1])\n",
    "\n",
    "            # 3: fit ex\n",
    "            print('Fitting random forest for e_x')\n",
    "            self.ex_model.fit(x, w)\n",
    "            probs = self.ex_model.predict_proba(x)[:, 1]\n",
    "            neg_prob = self.ex_model.predict_proba(x)[:, 0]\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            mu_w = w * self.mu1_model.predict(x) + (1 - w) * self.mu0_model.predict(x)\n",
    "            pseudo_outcomes = (w - probs) / (probs * neg_prob) * (y - mu_w) + self.mu1_model.predict(\n",
    "                x) - self.mu0_model.predict(x)\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Fitting random forest for tau_x')\n",
    "            self.tau_model.fit(x, pseudo_outcomes)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_train = self.poly.fit_transform(x)\n",
    "\n",
    "            # 1: fit mu_0\n",
    "            print('Fitting lasso for mu_0')\n",
    "            self.mu0_model.fit(x_poly_train[w == 0], y[w == 0])\n",
    "\n",
    "            # 2: fit mu_1\n",
    "            print('Fitting lasso for mu_1')\n",
    "            self.mu1_model.fit(x_poly_train[w == 1], y[w == 1])\n",
    "\n",
    "            # 3: fit ex\n",
    "            print('Fitting lasso for e_x')\n",
    "            self.ex_model.fit(x_poly_train, w)\n",
    "            probs = self.ex_model.predict_proba(x_poly_train)[:, 1]\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            mu_w = w * self.mu1_model.predict(x_poly_train) + (1 - w) * self.mu0_model.predict(x_poly_train)\n",
    "            pseudo_outcomes = (w - probs) / (probs * (1 - probs)) * (y - mu_w) + self.mu1_model.predict(\n",
    "                x_poly_train) - self.mu0_model.predict(x_poly_train)\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Fitting lasso for tau_x')\n",
    "            self.tau_model.fit(x_poly_train, pseudo_outcomes)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "            w = tf.convert_to_tensor(w)\n",
    "\n",
    "            # 1: fit mu_0\n",
    "            print('Training NN for mu_0')\n",
    "            self.mu0_model.fit(x[w == 0], y[w == 0],\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "            # 2: fit mu_1\n",
    "            print('Training NN for mu_1')\n",
    "            self.mu1_model.fit(x[w == 1], y[w == 1],\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "            # 3: fit ex\n",
    "            print('Training NN for e_x')\n",
    "            self.ex_model.fit(x, w,\n",
    "                              batch_size=100,\n",
    "                              epochs=100,\n",
    "                              callbacks=None,\n",
    "                              verbose=0\n",
    "                              )\n",
    "\n",
    "            probs = tf.reshape(keras.activations.sigmoid(self.ex_model(x)), len(x, ))\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            mu_0_hats = self.mu0_model(x)\n",
    "            mu_1_hats = self.mu1_model(x)\n",
    "\n",
    "            mu_w = w * mu_1_hats + (1 - w) * mu_0_hats\n",
    "            pseudo_outcomes = (w - probs) / (probs * (1 - probs)) * (y - mu_w) + mu_1_hats - mu_0_hats\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Training NN for tau_x')\n",
    "            self.tau_model.fit(x, pseudo_outcomes,\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               validation_data=None,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            predictions = self.tau_model.predict(x)\n",
    "\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_test = self.poly.fit_transform(x)\n",
    "            predictions = self.tau_model.predict(x_poly_test)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            # predict\n",
    "            predictions = np.reshape(self.tau_model(x), (len(x),))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dr_rf = DRLearner('nn')\n",
    "dr_rf.fit(X_train, Y_train, W_train)\n",
    "predictions = dr_rf.predict(X_test)\n",
    "((predictions - tau_test) ** 2).mean()\n",
    "# rf: 5.385491721300538 # why different??? ---> because if you take 1 - probs it is not exactly the same as taking the [:,0] column!!\n",
    "# lasso: 6.252082321980517\n",
    "# nn: 8.35142898943478"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CHECK THIS: CHANGE (1 - PROBS) TO [:,0] TO BE MORE EXACT!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class RA-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RALearner:\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "        if method == 'rf':\n",
    "            self.mu0_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.mu1_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.tau_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "\n",
    "        elif method == 'lasso':\n",
    "            self.mu0_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.mu1_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.tau_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "\n",
    "        elif method == 'nn':\n",
    "            self.mu0_model = load_model('model_25')\n",
    "            self.mu1_model = load_model('model_25')\n",
    "            self.tau_model = load_model('model_25')\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified or typo')\n",
    "\n",
    "    def fit(self, x, y, w):\n",
    "        if self.method == 'rf':\n",
    "            # 1: fit mu_0\n",
    "            print('Fitting random forest for mu_0')\n",
    "            self.mu0_model.fit(x[w == 0], y[w == 0])\n",
    "\n",
    "            # 2: fit mu_1\n",
    "            print('Fitting random forest for mu_1')\n",
    "            self.mu1_model.fit(x[w == 1], y[w == 1])\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            pseudo_outcomes = w * (y - self.mu0_model.predict(x)) + (1 - w) * (self.mu1_model.predict(x) - y)\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Fitting random forest for tau_x')\n",
    "            self.tau_model.fit(x, pseudo_outcomes)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_train = self.poly.fit_transform(x)\n",
    "\n",
    "            # 1: fit mu_0\n",
    "            print('Fitting lasso for mu_0')\n",
    "            self.mu0_model.fit(x_poly_train[w == 0], y[w == 0])\n",
    "\n",
    "            # 2: fit mu_1\n",
    "            print('Fitting lasso for mu_1')\n",
    "            self.mu1_model.fit(x_poly_train[w == 1], y[w == 1])\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            pseudo_outcomes = w * (y - self.mu0_model.predict(x_poly_train)) + (1 - w) * (\n",
    "                    self.mu1_model.predict(x_poly_train) - y)\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Fitting lasso for tau_x')\n",
    "            self.tau_model.fit(x_poly_train, pseudo_outcomes)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "            w = tf.convert_to_tensor(w)\n",
    "\n",
    "            # 1: fit mu_0\n",
    "            print('Training NN for mu_0')\n",
    "            self.mu0_model.fit(x[w == 0], y[w == 0],\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "            # 2: fit mu_1\n",
    "            print('Training NN for mu_1')\n",
    "            self.mu1_model.fit(x[w == 1], y[w == 1],\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            mu0_predictions = np.reshape(self.mu0_model(x), (len(x),))\n",
    "            mu1_predictions = np.reshape(self.mu1_model(x), (len(x),))\n",
    "\n",
    "            pseudo_outcomes = w * (y - mu0_predictions) + (1 - w) * (mu1_predictions - y)\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Training NN for tau_x')\n",
    "            self.tau_model.fit(x, pseudo_outcomes,\n",
    "                               batch_size=100,\n",
    "                               epochs=100,\n",
    "                               validation_data=None,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.method == 'rf':\n",
    "            predictions = self.tau_model.predict(x)\n",
    "\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_test = self.poly.fit_transform(x)\n",
    "            predictions = self.tau_model.predict(x_poly_test)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            # predict\n",
    "            predictions = np.reshape(self.tau_model(x), (len(x),))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ra_rf = RALearner('nn')\n",
    "ra_rf.fit(X_train, Y_train, W_train)\n",
    "predictions = ra_rf.predict(X_test)\n",
    "((predictions - tau_test) ** 2).mean()\n",
    "# rf: 5.355494017645751\n",
    "# lasso: 8.283890654355236\n",
    "# nn: 3.3973654461530867\n",
    "\n",
    "# 3.353439795888397\n",
    "# 3.3534397958883955"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class PW-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PWLearner:\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "        if method == 'rf':\n",
    "            self.ex_model = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "            self.tau_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "\n",
    "        elif method == 'lasso':\n",
    "            self.ex_model = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "            self.tau_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "            self.poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "\n",
    "        elif method == 'nn':\n",
    "            self.ex_1_model = load_model('model_ex')\n",
    "            self.ex_2_model = load_model('model_ex')\n",
    "            self.tau_model = load_model('model_25')\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified or typo')\n",
    "\n",
    "    def fit(self, x, y, w):\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            # 3: fit ex\n",
    "            print('Fitting random forest for e_x')\n",
    "            self.ex_model.fit(x, w)\n",
    "            probs = self.ex_model.predict_proba(x)[:, 1]\n",
    "            counter_probs = self.ex_model.predict_proba(x)[:, 0]\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            pseudo_outcomes = (w / probs - (1 - w) / counter_probs) * y\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Fitting random forest for tau_x')\n",
    "            self.tau_model.fit(x, pseudo_outcomes)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_train = self.poly.fit_transform(x)\n",
    "\n",
    "            # 3: fit ex\n",
    "            print('Fitting lasso for e_x')\n",
    "            self.ex_model.fit(x_poly_train, w)\n",
    "\n",
    "            probs = self.ex_model.predict_proba(x_poly_train)[:, 1]\n",
    "            counter_probs = self.ex_model.predict_proba(x_poly_train)[:, 0]\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            pseudo_outcomes = (w / probs - (1 - w) / counter_probs) * y\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Fitting lasso for tau_x')\n",
    "            self.tau_model.fit(x_poly_train, pseudo_outcomes)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            y = tf.convert_to_tensor(y)\n",
    "            w = tf.convert_to_tensor(w)\n",
    "\n",
    "            # cross-fitting\n",
    "            # split for cross-fitting\n",
    "            index = np.zeros(len(x), dtype=bool)\n",
    "            train_ind = np.random.choice(len(x), int(len(x) / 2), replace=False)\n",
    "            index[train_ind] = 1\n",
    "\n",
    "            probs = np.zeros(len(x), )\n",
    "\n",
    "            # 3: fit ex\n",
    "            print('Training NN for e_x')\n",
    "\n",
    "            self.ex_1_model.fit(x[index], w[index],\n",
    "                                batch_size=100,\n",
    "                                epochs=50,\n",
    "                                callbacks=None,\n",
    "                                verbose=0\n",
    "                                )\n",
    "\n",
    "            self.ex_2_model.fit(x[~index], w[~index],\n",
    "                                batch_size=100,\n",
    "                                epochs=50,\n",
    "                                callbacks=None,\n",
    "                                verbose=0\n",
    "                                )\n",
    "\n",
    "            probs[index] = tf.squeeze(keras.activations.sigmoid(self.ex_1_model(x[index])))\n",
    "            probs[~index] = tf.squeeze(keras.activations.sigmoid(self.ex_2_model(x[~index])))\n",
    "\n",
    "            # probs = tf.squeeze(keras.activations.sigmoid(self.ex_model(x)))\n",
    "            counter_probs = 1 - probs\n",
    "\n",
    "            # calculate pseudo_outcomes\n",
    "            pseudo_outcomes = (w / probs - (1 - w) / counter_probs) * y\n",
    "\n",
    "            # 4 fit tau\n",
    "            print('Training NN for tau_x')\n",
    "            self.tau_model.fit(x, pseudo_outcomes,\n",
    "                               batch_size=100,\n",
    "                               epochs=50,\n",
    "                               validation_data=None,\n",
    "                               callbacks=None,\n",
    "                               verbose=0\n",
    "                               )\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.method == 'rf':\n",
    "            predictions = self.tau_model.predict(x)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            x_poly_test = self.poly.fit_transform(x)\n",
    "            predictions = self.tau_model.predict(x_poly_test)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            predictions = np.array(self.tau_model(x)).squeeze()\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pw_rf = PWLearner('nn')\n",
    "pw_rf.fit(X_train, Y_train, W_train)\n",
    "predictions = pw_rf.predict(X_test)\n",
    "((predictions - tau_test) ** 2).mean()\n",
    "# rf: 30.529802728890644\n",
    "# lasso: 16.03059004204301\n",
    "# nn: 271.8425349295992\n",
    "\n",
    "# 238.41087366274616"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class U-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ULearner:\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "\n",
    "        if method == 'rf':\n",
    "            self.tau_model = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "\n",
    "        elif method == 'lasso':\n",
    "            self.tau_model = LassoCV(cv=10, tol=1, random_state=0)\n",
    "\n",
    "        elif method == 'nn':\n",
    "            self.tau_model = load_model('model_25')\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified or typo')\n",
    "\n",
    "    def compute_hats_rf(self, x_train, y_train, w_train, x_test):\n",
    "        # 1: fit mu_x\n",
    "        print('Fitting random forest for mu_x')\n",
    "        temp_mux = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=0)\n",
    "        temp_mux.fit(x_train, y_train)\n",
    "        # 2: fit ex\n",
    "        temp_ex = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "        temp_ex.fit(x_train, w_train)\n",
    "        # residuals\n",
    "        probs = temp_ex.predict_proba(x_test)[:, 1]\n",
    "        mux_hat = temp_mux.predict(x_test)\n",
    "        return mux_hat, probs\n",
    "\n",
    "    def compute_hats_lasso(self, x_train, y_train, w_train, x_test):\n",
    "        # poly transformation\n",
    "        transformer = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "        x_poly_train = transformer.fit_transform(x_train)\n",
    "        x_poly_test = transformer.fit_transform(x_test)\n",
    "\n",
    "        # 1: fit mu_x\n",
    "        print('Fitting random forest for mu_x')\n",
    "        temp_mux = LassoCV(cv=10, tol=1, random_state=0)\n",
    "        temp_mux.fit(x_poly_train, y_train)\n",
    "        # 2: fit ex\n",
    "        temp_ex = LogisticRegressionCV(cv=KFold(10), penalty='l1', solver='saga', tol=1, random_state=0)\n",
    "        temp_ex.fit(x_poly_train, w_train)\n",
    "        # residuals\n",
    "        probs = temp_ex.predict_proba(x_poly_test)[:, 1]\n",
    "        mux_hat = temp_mux.predict(x_poly_test)\n",
    "        return mux_hat, probs\n",
    "\n",
    "    def compute_hats_nn(x_train, y_train, w_train, x_test):\n",
    "        # to tensor\n",
    "        x_train = tf.convert_to_tensor(x_train)\n",
    "        y_train = tf.convert_to_tensor(y_train)\n",
    "        w_train = tf.convert_to_tensor(w_train)\n",
    "        # 1: fit mu_x\n",
    "        print('Fitting random forest for mu_x')\n",
    "        temp_mux = load_model('model_25')\n",
    "        temp_mux.fit(x_train, y_train, batch_size=100, epochs=50, callbacks=None, verbose=0)\n",
    "        # 2: fit ex\n",
    "        temp_ex = load_model('model_ex')\n",
    "        temp_ex.fit(x_train, w_train, batch_size=100, epochs=50, callbacks=None, verbose=0)\n",
    "        # residuals\n",
    "        probs = tf.squeeze(keras.activations.sigmoid(temp_ex(x_test)))\n",
    "        mux_hat = tf.squeeze(temp_mux(x_test))\n",
    "        return mux_hat, probs\n",
    "\n",
    "    def fit(self, x, y, w):\n",
    "\n",
    "        # if no cross-fitting\n",
    "        if self.method == 'rf':\n",
    "            if CF_FOLDS == 1:\n",
    "                mux_hat, probs = self.compute_hats_rf(x, y, w, x)\n",
    "\n",
    "        # cross-fitting\n",
    "            else:\n",
    "                # initialize\n",
    "                mux_hat = np.zeros(700)\n",
    "                probs = np.zeros(700)\n",
    "                # cross-fitting\n",
    "                stratified = StratifiedKFold(n_splits=CF_FOLDS, shuffle=True, random_state=0)\n",
    "                for train_index, test_index in stratified.split(x, w):\n",
    "                    index = np.zeros(700, dtype=bool)\n",
    "                    index[test_index] = 1\n",
    "                    print('Fitting Classifier')\n",
    "                    mux_hat[~index], probs[~index] =  self.compute_hats_rf(x[index], y[index], w[index], x[~index] )\n",
    "            residuals = (y - mux_hat) / (w - probs)\n",
    "            # 3: fit tau\n",
    "            print('Fitting random forest for tau_x')\n",
    "            self.tau_model.fit(x, residuals)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            if CF_FOLDS == 1:\n",
    "                mux_hat, probs = self.compute_hats_lasso(x, y, w, x)\n",
    "\n",
    "            else:\n",
    "                # initialize\n",
    "                mux_hat = np.zeros(700)\n",
    "                probs = np.zeros(700)\n",
    "                # cross-fitting\n",
    "                stratified = StratifiedKFold(n_splits=CF_FOLDS, shuffle=True, random_state=0)\n",
    "                for train_index, test_index in stratified.split(x, w):\n",
    "                    index = np.zeros(700, dtype=bool)\n",
    "                    index[test_index] = 1\n",
    "                    print('Fitting Classifier')\n",
    "                    mux_hat[~index], probs[~index] =  self.compute_hats_lasso(x[index], y[index], w[index], x[~index] )\n",
    "            residuals = (y - mux_hat) / (w - probs)\n",
    "            # 3: fit tau\n",
    "            print('Fitting random forest for tau_x')\n",
    "            transformer = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "            x_poly = transformer.fit_transform(x)\n",
    "            self.tau_model.fit(x_poly, residuals)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "\n",
    "            if CF_FOLDS == 1:\n",
    "                mux_hat, probs = self.compute_hats_nn(x, y, w, x)\n",
    "\n",
    "            else:\n",
    "                # initialize\n",
    "                mux_hat = np.zeros(700)\n",
    "                probs = np.zeros(700)\n",
    "                # cross-fitting\n",
    "                stratified = StratifiedKFold(n_splits=CF_FOLDS, shuffle=True, random_state=0)\n",
    "                for train_index, test_index in stratified.split(x, w):\n",
    "                    index = np.zeros(700, dtype=bool)\n",
    "                    index[test_index] = 1\n",
    "                    print('Fitting Classifier')\n",
    "                    mux_hat[~index], probs[~index] =  self.compute_hats_nn(x[index], y[index], w[index], x[~index] )\n",
    "            residuals = (y - mux_hat) / (w - probs)\n",
    "            # 3: fit tau\n",
    "            print('Fitting random forest for tau_x')\n",
    "            self.tau_model.fit(x, residuals, batch_size=100, epochs=50, callbacks=None, verbose=0)\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        if self.method == 'rf':\n",
    "            predictions = self.tau_model.predict(x)\n",
    "\n",
    "        elif self.method == 'lasso':\n",
    "            transformer = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "            x_poly_test = transformer.fit_transform(x)\n",
    "            predictions = self.tau_model.predict(x_poly_test)\n",
    "\n",
    "        elif self.method == 'nn':\n",
    "            # to tensor\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            # predict\n",
    "            predictions = np.reshape(self.tau_model(x), (len(x),))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('Base learner method not specified in predict')\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u_rf = ULearner('nn')\n",
    "u_rf.fit(X_train, Y_train, W_train)\n",
    "predictions = u_rf.predict(X_test)\n",
    "np.sqrt((((predictions - tau_test) ** 2).mean()))\n",
    "# rf: 30.921286420155806\n",
    "# lasso: 7.6762472449663495\n",
    "# nn: 51.10236987028663\n",
    "\n",
    "# 31.033895213307428\n",
    "# 31.033895213307698\n",
    "\n",
    "\n",
    "# with cross-fitting much better now :)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CF_FOLDS = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "try stratifiedfolds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: THATS IT!!!!!\n",
    "w_hats = np.zeros(700)\n",
    "\n",
    "stratified = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n",
    "for train_index, test_index in stratified.split(X_train, W_train):\n",
    "    index = np.zeros(700, dtype=bool)\n",
    "    index[test_index] = 1\n",
    "    print('Fitting Classifier')\n",
    "    temp_model = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "    temp_model.fit(X_train[index], W_train[index])\n",
    "    w_hats[~index] = temp_model.predict_proba(X_train[~index])[:, 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stratified = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n",
    "for train_index, test_index in stratified.split(X_train, W_train):\n",
    "    index = np.zeros(700, dtype=bool)\n",
    "    index[test_index] = 1\n",
    "    print(index)\n",
    "    print(~index)\n",
    "    print(tf.convert_to_tensor(index))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_hats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_hats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = np.zeros(700, dtype=bool)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# END"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w = np.zeros((700,))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lol = load_model('model_ex')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lol.fit(X_train, w, batch_size=100, epochs=400, callbacks=callback, validation_split=0.3, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.activations.sigmoid(lol.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try out some stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, max_features=0.3, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.fit(X_train, W_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.predict_proba(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.predict_proba(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CROSS-FITTING WILL PROBABLY SOLVE THE PROBLEM!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.predict(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.ones(100, dtype=bool)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_mask = torch.zeros(100, dtype=bool)\n",
    "pred_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "~pred_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hasattr(rf, 'predict')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_class = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hasattr(rf_class, 'train')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lasso = LassoCV()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hasattr(lasso, 'predict_proba')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MyModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(8953)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dimension=FEATURE_DIMENSION,\n",
    "            n_layers_1=3,\n",
    "            n_layers_2=2,\n",
    "            n_units_1=N_UNITS_FIRST_PART,\n",
    "            n_units_2=N_UNITS_SECOND_PART,\n",
    "            activation=NON_LINEARITY,\n",
    "            regularizer=regularizers.L2(1e-4)):\n",
    "        super().__init__()\n",
    "        self.input_dimension = input_dimension\n",
    "        self.n_layers_1 = n_layers_1\n",
    "        self.n_layers_2 = n_layers_2\n",
    "        self.n_units_1 = n_units_1\n",
    "        self.n_units_2 = n_units_2\n",
    "        self.activation = activation\n",
    "        self.regularizer = regularizer\n",
    "\n",
    "        self.dense1 = layers.Dense(units=self.n_units_1, activation=self.activation, name=\"layer1\",\n",
    "                                   kernel_regularizer=self.regularizer)\n",
    "        self.dense2 = layers.Dense(units=self.n_units_1, activation=self.activation, name=\"layer2\",\n",
    "                                   kernel_regularizer=self.regularizer)\n",
    "        self.dense3 = layers.Dense(units=self.n_units_1, activation=self.activation, name=\"layer3\",\n",
    "                                   kernel_regularizer=self.regularizer)\n",
    "        self.dense4 = layers.Dense(units=self.n_units_2, activation=self.activation, name=\"layer4\",\n",
    "                                   kernel_regularizer=self.regularizer)\n",
    "        self.dense5 = layers.Dense(units=self.n_units_2, activation=self.activation, name=\"layer5\",\n",
    "                                   kernel_regularizer=self.regularizer)\n",
    "        self.dense6 = layers.Dense(units=1, activation='linear', name=\"layer6\",\n",
    "                                   kernel_regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = MyModel()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              # List of metrics to monitor\n",
    "              metrics=[keras.metrics.MeanSquaredError()],\n",
    "              # weighted metrics\n",
    "              weighted_metrics=[]\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TRY"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3 layers with 200 units (elu activation), 2 layers with 100 units (elu activations), 1 output layer (linear\n",
    "# activation)\n",
    "model1 = keras.Sequential([\n",
    "    keras.Input(shape=(25,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"linear\", name=\"layer6\"),\n",
    "\n",
    "], name=\"model_25\")\n",
    "\n",
    "# compile the model\n",
    "model1.compile(\n",
    "    optimizer=keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    "    # weighted metrics\n",
    "    weighted_metrics=[]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.clone_model(model1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1.fit(X_train, Y_train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer=keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    "    # weighted metrics\n",
    "    weighted_metrics=[]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2.fit(X_train, Y_train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clone_model_regression(model):\n",
    "    cloned_model = tf.keras.models.clone_model(model)\n",
    "    cloned_model.compile(\n",
    "        optimizer=keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
    "        # Loss function to minimize\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        # List of metrics to monitor\n",
    "        metrics=[keras.metrics.MeanSquaredError()],\n",
    "        # weighted metrics\n",
    "        weighted_metrics=[]\n",
    "    )\n",
    "    return cloned_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloned_model = clone_model_regression(model1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cloned_model.fit(X_train, Y_train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clone_model_classification(model):\n",
    "    cloned_model = tf.keras.models.clone_model(model)\n",
    "    cloned_model.compile(\n",
    "        optimizer=keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
    "        # Loss function to minimize\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        # List of metrics to monitor\n",
    "        metrics=[keras.metrics.MeanSquaredError()],\n",
    "        # weighted metrics\n",
    "        weighted_metrics=[]\n",
    "    )\n",
    "    return cloned_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from HelperFuctions import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_nn = keras.Sequential([\n",
    "    keras.Input(shape=(25,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"linear\", name=\"layer6\"),\n",
    "], name=\"model_sequential\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_nn_1 = keras.Sequential([\n",
    "    keras.Input(shape=(26,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"linear\", name=\"layer6\"),\n",
    "], name=\"model_sequential_1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_mu = clone_model_regression(model_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_ex = clone_model_classification(model_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_mu.fit(X_train, Y_train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from NeuralNetworks import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from HelperFuctions import *\n",
    "from NeuralNetworks import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1 = clone_nn_regression(nn_sequential)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1.fit(X_train[:, 0:20], Y_train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = clone_nn_regression(nn_sequential)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2.fit(X_train[:, 0:20], Y_train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1 = clone_nn_regression(nn_sequential)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
