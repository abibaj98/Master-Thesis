{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:00.347668Z",
     "start_time": "2023-07-04T01:34:58.583743Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import stats\n",
    "# import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import r packages if needed\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "rpackages.importr(\"clusterGeneration\")\n",
    "rpackages.importr(\"mpower\")\n",
    "rpackages.importr(\"base\")\n",
    "rpackages.importr(\"utils\")\n",
    "cluster_generation = robjects.packages.importr(\"clusterGeneration\")\n",
    "mpower = robjects.packages.importr(\"mpower\")\n",
    "base = robjects.packages.importr(\"base\")\n",
    "utils = robjects.packages.importr(\"utils\")\n",
    "\n",
    "# set seed from R\n",
    "r = robjects.r\n",
    "set_seed = r('set.seed')\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fully Synthetic Data Sets (Set up from KÃ¼nzel et al.)\n",
    "\n",
    "# 1: Simulate the d-dimensional X.\n",
    "# 2: Create Potential Outcomes Y(1) and Y(0).\n",
    "# 3: Simulate Treatment Assignments trough W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if needed take student_t distributed errors to see simulation with heavy-tailed errors\n",
    "# e_o = random.standard_t(df=1,size=N)\n",
    "# e_1 = random.standard_t(df=1,size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# seeds for reproducibility --> NICE :-D\n",
    "set_seed(8953)  # R seed\n",
    "random.seed(8953)  # numpy seed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:09.332542Z",
     "start_time": "2023-07-04T01:35:09.321784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# SIMULATION SETUP: \"META-PARAMETERS\"\n",
    "sample_sizes = [500, 1000, 2000, 5000]  # TODO: change to [500, 1000, 2000, 5000]\n",
    "test_size = 1000\n",
    "n_runs = 1  # TODO: change to 10/30\n",
    "n_setups = 1  # TODO: change to 24\n",
    "d = 20  # TODO: change to 20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:28.678520Z",
     "start_time": "2023-07-04T01:35:28.676252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# all settings of e_x\n",
    "exs = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
    "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
    "       'beta_balanced', 'beta_balanced', 'beta_balanced', 'beta_balanced', 'beta_balanced', 'beta_balanced',\n",
    "       'beta_balanced',\n",
    "       'beta_unbalanced', 'beta_unbalanced', 'beta_unbalanced', 'beta_unbalanced', 'beta_unbalanced', 'beta_unbalanced',\n",
    "       'beta_unbalanced']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:34.004349Z",
     "start_time": "2023-07-04T01:35:33.991432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# all settings of mu_0 / mu_1\n",
    "cates = ['linear_response', 'non_linear_response', 'indicator_cate', 'linear_cate', 'complex_linear_cate',\n",
    "         'complex_non_linear_cate'] * 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:42.530050Z",
     "start_time": "2023-07-04T01:35:42.515067Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cate Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1: linear response (zero cate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def linear_response(x_train, x_test):\n",
    "    betas = random.uniform(low=-5, high=5, size=x_train.shape[1])\n",
    "\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x_train, betas) + 5 * x_train[:, 0]\n",
    "    mu_1 = mu_0\n",
    "    tau = np.zeros(len(x_train))\n",
    "\n",
    "    # test set\n",
    "    mu_0_test = np.matmul(x_test, betas) + 5 * x_test[:, 0]\n",
    "    mu_1_test = mu_0_test\n",
    "    tau_test = np.zeros(len(x_test))\n",
    "\n",
    "    return mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:44.434974Z",
     "start_time": "2023-07-04T01:35:44.431115Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2: non-linear response (zero cate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def non_linear_response(x_train, x_test):\n",
    "    # train set\n",
    "    mu_0 = np.arctan(x_train[:, 0]) * np.arctan(x_train[:, 1])\n",
    "    mu_1 = mu_0\n",
    "    tau = np.zeros(len(x_train))\n",
    "\n",
    "    # test set\n",
    "    mu_0_test = np.arctan(x_test[:, 0]) * np.arctan(x_test[:, 1])\n",
    "    mu_1_test = mu_0_test\n",
    "    tau_test = np.zeros(len(x_test))\n",
    "\n",
    "    return mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:44.756477Z",
     "start_time": "2023-07-04T01:35:44.751669Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3: simple indicator cate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def simple_indicator_cate(x_train, x_test):\n",
    "    betas = random.uniform(low=-5, high=5, size=x_train.shape[1])\n",
    "\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x_train, betas) + 5 * np.int8(x_train[:, 0] > 0.5)\n",
    "    mu_1 = mu_0 + 8 * np.int8(x_train[:, 1] > 0.1)\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    # test set\n",
    "    mu_0_test = np.matmul(x_test, betas) + 5 * np.int8(x_test[:, 0] > 0.5)\n",
    "    mu_1_test = mu_0_test + 8 * np.int8(x_test[:, 1] > 0.1)\n",
    "    tau_test = mu_1_test - mu_0_test\n",
    "\n",
    "    return mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:45.158761Z",
     "start_time": "2023-07-04T01:35:45.153999Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4: simple linear cate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def simple_linear_cate(x_train, x_test):\n",
    "    betas = random.uniform(low=-5, high=5, size=x_train.shape[1])\n",
    "\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x_train, betas) + 5 * x_train[:, 0]\n",
    "    mu_1 = mu_0 + 8 * x_train[:, 1]\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    # test set\n",
    "    mu_0_test = np.matmul(x_test, betas) + 5 * x_test[:, 0]\n",
    "    mu_1_test = mu_0_test + 8 * x_test[:, 1]\n",
    "    tau_test = mu_1_test - mu_0_test\n",
    "\n",
    "    return mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:45.430104Z",
     "start_time": "2023-07-04T01:35:45.425446Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5: complex linear cate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def complex_linear_cate(x_train, x_test):\n",
    "    betas_0 = random.uniform(low=-5, high=5, size=x_train.shape[1])\n",
    "    betas_1 = random.uniform(low=-5, high=5, size=x_train.shape[1])\n",
    "\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x_train, betas_0) + 5 * x_train[:, 0]\n",
    "    mu_1 = np.matmul(x_train, betas_1) + 5 * x_train[:, 0]\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    # test set\n",
    "    mu_0_test = np.matmul(x_test, betas_0) + 5 * x_test[:, 0]\n",
    "    mu_1_test = np.matmul(x_test, betas_1) + 5 * x_test[:, 0]\n",
    "    tau_test = mu_1_test - mu_0_test\n",
    "\n",
    "    return mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:45.719639Z",
     "start_time": "2023-07-04T01:35:45.716812Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6: complex non-linear cate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# helper function varsigma\n",
    "def varsigma_function(x):\n",
    "    return 2 / (1 + np.exp(-12 * (x - 1 / 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:45.974109Z",
     "start_time": "2023-07-04T01:35:45.970475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def complex_non_linear_cate(x_train, x_test):\n",
    "    # train set\n",
    "    mu_0 = -1 / 2 * varsigma_function(x_train[:, 0]) * varsigma_function(x_train[:, 1])\n",
    "    mu_1 = 1 / 2 * varsigma_function(x_train[:, 0]) * varsigma_function(x_train[:, 1])\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    # test set\n",
    "    mu_0_test = -1 / 2 * varsigma_function(x_test[:, 0]) * varsigma_function(x_test[:, 1])\n",
    "    mu_1_test = 1 / 2 * varsigma_function(x_test[:, 0]) * varsigma_function(x_test[:, 1])\n",
    "    tau_test = mu_1_test - mu_0_test\n",
    "\n",
    "    return mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:46.374181Z",
     "start_time": "2023-07-04T01:35:46.371789Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Propensity settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# helper function\n",
    "def beta_balanced(x_train, x_test):\n",
    "    beta_dist = stats.beta(a=2, b=4)  # set beta distribution\n",
    "\n",
    "    # train\n",
    "    cdf_values = stats.norm.cdf(x_train[:, 0])\n",
    "    beta_values = beta_dist.pdf(cdf_values)  # calculate pdf values for x1\n",
    "    e_x = 1 / 4 * (1 + beta_values)\n",
    "\n",
    "    # test\n",
    "    cdf_values_test = stats.norm.cdf(x_test[:, 0])\n",
    "    beta_values_test = beta_dist.pdf(cdf_values_test)  # calculate pdf values for x1\n",
    "    e_x_test = 1 / 4 * (1 + beta_values_test)\n",
    "\n",
    "    return e_x, e_x_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:46.963464Z",
     "start_time": "2023-07-04T01:35:46.949035Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def beta_unbalanced(x_train, x_test):\n",
    "    beta_dist = stats.beta(a=2, b=4)  # set beta distribution\n",
    "\n",
    "    # train\n",
    "    cdf_values = stats.norm.cdf(x_train[:, 0])\n",
    "    beta_values = beta_dist.pdf(cdf_values)  # calculate pdf values for x1\n",
    "    e_x = 1 / 40 * (1 + beta_values)\n",
    "\n",
    "    # test\n",
    "    cdf_values_test = stats.norm.cdf(x_test[:, 0])\n",
    "    beta_values_test = beta_dist.pdf(cdf_values_test)  # calculate pdf values for x1\n",
    "    e_x_test = 1 / 40 * (1 + beta_values_test)\n",
    "\n",
    "    return e_x, e_x_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:47.407277Z",
     "start_time": "2023-07-04T01:35:47.404459Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### generate train/test set function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# TODO: TRIPLE CHECK THIS FUNCTION, IT IS VERY IMPORTANT\n",
    "def generate(ex, cate, sample_size, testing_size):\n",
    "    # 1: generated x_train & x_test\n",
    "    mean = np.zeros(d)\n",
    "    cov = np.array(mpower.cvine(d=d, alpha=0.5, beta=0.5))  # TODO: set cov according to setup\n",
    "    x_train = random.multivariate_normal(mean=mean, cov=cov, size=sample_size, check_valid='warn')\n",
    "    x_test = random.multivariate_normal(mean=mean, cov=cov, size=test_size, check_valid='warn')\n",
    "\n",
    "    # 2: generate e_0 & e_0\n",
    "    # train\n",
    "    e_0 = random.normal(loc=0.0, scale=1.0, size=sample_size)\n",
    "    e_1 = random.normal(loc=0.0, scale=1.0, size=sample_size)\n",
    "    # test\n",
    "    e_0_test = random.normal(loc=0.0, scale=1.0, size=testing_size)\n",
    "    e_1_test = random.normal(loc=0.0, scale=1.0, size=testing_size)\n",
    "\n",
    "    # 3: compute mu_0 & mu_1 --> based on setting\n",
    "    if cate == 'linear_response':  # 'linear response' setting (no treatment effect)\n",
    "        mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test = linear_response(x_train, x_test)\n",
    "\n",
    "    elif cate == 'non_linear_response':  # 'non-linear response' setting (no treatment effect)\n",
    "        mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test = non_linear_response(x_train, x_test)\n",
    "\n",
    "    elif cate == 'indicator_cate':  # 'simple indicator cate' setting\n",
    "        mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test = simple_indicator_cate(x_train, x_test)\n",
    "\n",
    "    elif cate == 'linear_cate':  # 'simple linear cate' setting\n",
    "        mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test = simple_linear_cate(x_train, x_test)\n",
    "\n",
    "    elif cate == 'complex_linear_cate':  # 'complex linear cate' setting\n",
    "        mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test = complex_linear_cate(x_train, x_test)\n",
    "\n",
    "    elif cate == 'complex_non_linear_cate':  # 'complex non-linear cate' setting\n",
    "        mu_0, mu_1, tau, mu_0_test, mu_1_test, tau_test = complex_non_linear_cate(x_train, x_test)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('No or incorrect setting specified.')\n",
    "\n",
    "    # 4: create potential outcomes y_0 & y_1\n",
    "    # train\n",
    "    y_0 = mu_0 + e_0\n",
    "    y_1 = mu_1 + e_1\n",
    "    # test\n",
    "    y_0_test = mu_0_test + e_0_test\n",
    "    y_1_test = mu_1_test + e_1_test\n",
    "\n",
    "    # 5: Set propensity score e_x --> based on setting\n",
    "    if isinstance(ex, float or int):\n",
    "        e_x = ex\n",
    "        e_x_test = ex\n",
    "\n",
    "    elif ex == 'beta_balanced':\n",
    "        e_x, e_x_test = beta_balanced(x_train, x_test)\n",
    "\n",
    "    elif ex == 'beta_unbalanced':\n",
    "        e_x, e_x_test = beta_unbalanced(x_train, x_test)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('Propensity method not or incorrectly specified.')\n",
    "\n",
    "    # 6: Generate treatment assignment W\n",
    "    w = random.binomial(size=sample_size, n=1, p=e_x)\n",
    "    w_test = random.binomial(size=testing_size, n=1, p=e_x_test)\n",
    "\n",
    "    # 7: Create observed variables Y\n",
    "    y = np.multiply(w, y_1) + np.multiply(np.ones(sample_size) - w, y_0)\n",
    "    y_test = np.multiply(w_test, y_1_test) + np.multiply(np.ones(testing_size) - w_test, y_0_test)\n",
    "\n",
    "    # 8: Create train & test sets\n",
    "    dataset_train = np.concatenate(\n",
    "        (np.reshape(y, (sample_size, 1)), x_train, np.reshape(w, (sample_size, 1)), np.reshape(tau, (sample_size, 1))),\n",
    "        axis=1)\n",
    "    dataset_test = np.concatenate((np.reshape(y_test, (testing_size, 1)), x_test, np.reshape(w_test, (testing_size, 1)),\n",
    "                                   np.reshape(tau_test, (testing_size, 1))), axis=1)\n",
    "\n",
    "    # 9: Return both sets\n",
    "    return [dataset_train, dataset_test]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:47.881231Z",
     "start_time": "2023-07-04T01:35:47.875476Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "empty list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# create empty list to save all datasets\n",
    "data = []\n",
    "for i in range(n_setups):\n",
    "    data.append([])\n",
    "\n",
    "for i in range(n_setups):\n",
    "    for s in range(4):\n",
    "        data[i].append([])\n",
    "\n",
    "for i in range(n_setups):\n",
    "    for s in range(4):\n",
    "        for r in range(n_runs):\n",
    "            data[i][s].append([])\n",
    "\n",
    "for i in range(n_setups):\n",
    "    for s in range(4):\n",
    "        for r in range(n_runs):\n",
    "            for t in range(2):\n",
    "                data[i][s][r].append([])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:49.378454Z",
     "start_time": "2023-07-04T01:35:49.374610Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### generate all"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating setup 1\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# generate all datasets\n",
    "s = 0\n",
    "for setup in range(n_setups):\n",
    "    print(f'Generating setup {setup + 1}')\n",
    "    for size in sample_sizes:\n",
    "        for run in range(n_runs):\n",
    "            gen = generate(ex=exs[setup], cate=cates[setup], sample_size=size, testing_size=test_size)\n",
    "            data[setup][s][run][0] = gen[0]  # add train-set\n",
    "            data[setup][s][run][1] = gen[1]  # add test-set\n",
    "        s += 1  # update index for sample_sizes\n",
    "    s = 0  # reset index for sample_sizes\n",
    "print('DONE')\n",
    "# it took 43 seconds # 4.4 GB of data!"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:35:51.705704Z",
     "start_time": "2023-07-04T01:35:51.652835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-2.10127177e+01,  9.86474306e-01, -4.92410122e-01, ...,\n         1.07541031e+00,  0.00000000e+00,  0.00000000e+00],\n       [-1.25542289e+01,  1.38759213e+00, -5.00854638e-01, ...,\n         2.55792858e-01,  0.00000000e+00,  0.00000000e+00],\n       [ 3.14445010e+01, -2.07217467e+00,  1.90524147e+00, ...,\n        -1.91588089e-01,  0.00000000e+00,  0.00000000e+00],\n       ...,\n       [-3.20361714e+01,  1.79728689e+00, -2.70657219e+00, ...,\n        -9.40858061e-01,  1.00000000e+00,  0.00000000e+00],\n       [-2.47035219e+01,  1.81272006e+00, -2.20742297e+00, ...,\n         1.31739761e-01,  0.00000000e+00,  0.00000000e+00],\n       [-4.88487478e+00, -6.87199711e-01, -9.47270940e-03, ...,\n        -1.01182862e+00,  1.00000000e+00,  0.00000000e+00]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][3][0][0]  # :)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:36:55.531333Z",
     "start_time": "2023-07-04T01:36:55.526185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 0.476460 -> reproducible :)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save data with pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# save data\n",
    "file_name = \"/Users/arberimbibaj/Documents/Master Thesis ETH/DataSets /Generated/data_synthetic_one_run.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(data, open_file)\n",
    "open_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:37:11.967109Z",
     "start_time": "2023-07-04T01:37:11.962631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.01167139,  1.13035656, -0.24136053, ..., -0.01064836,\n         1.        ,  0.        ],\n       [ 3.17020969,  0.22015068,  0.04529537, ...,  0.29755877,\n         1.        ,  0.        ],\n       [ 2.61769972,  0.37887061, -0.14322619, ...,  0.01384532,\n         0.        ,  0.        ],\n       ...,\n       [ 9.13235505, -0.28882811, -0.20802326, ...,  0.01642092,\n         1.        ,  0.        ],\n       [-9.11141269, -1.15419441,  1.81805704, ...,  1.56209178,\n         1.        ,  0.        ],\n       [ 0.80415229,  0.12075425, -0.41938106, ..., -0.27756771,\n         0.        ,  0.        ]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"/Users/arberimbibaj/Documents/Master Thesis ETH/DataSets /Generated/data_synthetic_one_run.pkl\"\n",
    "open_file = open(file_name, \"rb\")\n",
    "loaded_data = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "loaded_data[0][0][0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T01:37:14.159212Z",
     "start_time": "2023-07-04T01:37:14.150049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: CHANGE THIS BACK TO WHAT IT WAS, SO NO CRASHES CAN HAPPEN.\n",
    "# Current values:\n",
    "# NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
    "# NotebookApp.rate_limit_window=3.0 (secs)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
