{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import stats\n",
    "import jsonpickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import r packages if needed\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.packages as rpackages\n",
    "\n",
    "rpackages.importr(\"mpower\")\n",
    "mpower = robjects.packages.importr(\"mpower\")\n",
    "\n",
    "# set seed from R\n",
    "r = robjects.r\n",
    "set_seed = r('set.seed')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# seeds for reproducibility --> NICE :-D\n",
    "set_seed(8953)  # R seed\n",
    "random.seed(8953)  # numpy seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SIMULATION SETUP: \"META-PARAMETERS\"\n",
    "sample_sizes = [500, 1000, 2000, 5000]  # TODO: change to [500, 1000, 2000, 5000]\n",
    "test_size = 1000\n",
    "n_runs = 10  # TODO: change to 10/30\n",
    "n_setups = 18  # TODO: change to 28 ???\n",
    "d = 20  # TODO: change to 20"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all settings of e_x\n",
    "exs = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5,  # settings 1-6\n",
    "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1,  # settings 7-12\n",
    "       'beta_balanced', 'beta_balanced', 'beta_balanced', 'beta_balanced', 'beta_balanced',\n",
    "       'beta_balanced']  # settings 13-18"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all settings of mu_0 / mu_1\n",
    "cates = ['linear_response', 'non_linear_response', 'indicator_cate', 'linear_cate', 'complex_linear_cate',\n",
    "         'complex_non_linear_cate'] * 3  # TODO: change to 3!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def linear_response(x, betas):\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x, betas) + 5 * x[:, 0]\n",
    "    mu_1 = mu_0\n",
    "    tau = np.zeros(len(x))\n",
    "\n",
    "    return mu_0, mu_1, tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: multiple by 5/10!\n",
    "def non_linear_response(x):\n",
    "    # train set\n",
    "    mu_0 = 5 * np.arctan(x[:, 0]) * np.arctan(x[:, 1])\n",
    "    mu_1 = mu_0\n",
    "    tau = np.zeros(len(x))\n",
    "\n",
    "    return mu_0, mu_1, tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simple_indicator_cate(x, betas):\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x, betas) + 5 * np.int8(x[:, 0] > 0.5)\n",
    "    mu_1 = mu_0 + 8 * np.int8(x[:, 1] > 0.1)\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    return mu_0, mu_1, tau\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simple_linear_cate(x, betas):\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x, betas) + 5 * x[:, 0]\n",
    "    mu_1 = mu_0 + 4 * x[:, 1] + 2  # TODO: what to change?\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    return mu_0, mu_1, tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def complex_linear_cate(x, betas_0, betas_1):\n",
    "    # train set\n",
    "    mu_0 = np.matmul(x, betas_0) + 5 * x[:, 0]\n",
    "    mu_1 = np.matmul(x, betas_1) + 5 * x[:, 0]\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    return mu_0, mu_1, tau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: also multiple to scale outcomes\n",
    "# helper function varsigma\n",
    "def varsigma_function(x):\n",
    "    return 2 / (1 + np.exp(-12 * x))  # TODO: before, it was (x - 0,5).\n",
    "\n",
    "\n",
    "def complex_non_linear_cate(x):\n",
    "    # train set\n",
    "    mu_0 = -4 / 2 * varsigma_function(x[:, 0]) * varsigma_function(x[:, 1])\n",
    "    mu_1 = 4 / 2 * varsigma_function(x[:, 0]) * varsigma_function(x[:, 1])\n",
    "    tau = mu_1 - mu_0\n",
    "\n",
    "    return mu_0, mu_1, tau\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# helper function\n",
    "def beta_balanced(x):\n",
    "    beta_dist = stats.beta(a=2, b=4)  # set beta distribution\n",
    "\n",
    "    # train\n",
    "    cdf_values = stats.norm.cdf(x[:, 0])\n",
    "    beta_values = beta_dist.pdf(cdf_values)  # calculate pdf values for x1\n",
    "    e_x = 1 / 4 * (1 + beta_values)\n",
    "\n",
    "    return e_x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_X = np.zeros(d)\n",
    "cov_X = np.array(mpower.cvine(d=d, alpha=0.5, beta=0.5))\n",
    "X = random.multivariate_normal(mean=mean_X, cov=cov_X, size=1000, check_valid='warn')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  TODO: TRIPLE CHECK THIS FUNCTION, IT IS VERY IMPORTANT\n",
    "\n",
    "def generate_data(mean, cov, ex, cate, sample_size, betas, betas_0, betas_1):\n",
    "    # 1: generated x_train & x_test\n",
    "    x_train = random.multivariate_normal(mean=mean, cov=cov, size=sample_size, check_valid='warn')\n",
    "\n",
    "    # 2: generate e_0 & e_0\n",
    "    e_0 = random.normal(loc=0.0, scale=1.0, size=sample_size)\n",
    "    e_1 = random.normal(loc=0.0, scale=1.0, size=sample_size)\n",
    "\n",
    "    # 3: compute mu_0 & mu_1 --> based on setting\n",
    "    if cate == 'linear_response':  # 'linear response' setting (no treatment effect)\n",
    "        mu_0, mu_1, tau = linear_response(x_train, betas)\n",
    "\n",
    "    elif cate == 'non_linear_response':  # 'non-linear response' setting (no treatment effect)\n",
    "        mu_0, mu_1, tau = non_linear_response(x_train)\n",
    "\n",
    "    elif cate == 'indicator_cate':  # 'simple indicator cate' setting\n",
    "        mu_0, mu_1, tau = simple_indicator_cate(x_train, betas)\n",
    "\n",
    "    elif cate == 'linear_cate':  # 'simple linear cate' setting\n",
    "        mu_0, mu_1, tau = simple_linear_cate(x_train, betas)\n",
    "\n",
    "    elif cate == 'complex_linear_cate':  # 'complex linear cate' setting\n",
    "        mu_0, mu_1, tau = complex_linear_cate(x_train, betas_0, betas_1)\n",
    "\n",
    "    elif cate == 'complex_non_linear_cate':  # 'complex non-linear cate' setting\n",
    "        mu_0, mu_1, tau = complex_non_linear_cate(x_train)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('No or incorrect setting specified.')\n",
    "\n",
    "    # 4: create potential outcomes y_0 & y_1\n",
    "    # train\n",
    "    y_0 = mu_0 + e_0\n",
    "    y_1 = mu_1 + e_1\n",
    "\n",
    "    # 5: Set propensity score e_x --> based on setting\n",
    "    if isinstance(ex, float or int):\n",
    "        e_x = ex\n",
    "\n",
    "    elif ex == 'beta_balanced':\n",
    "        e_x = beta_balanced(x_train)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('Propensity method not or incorrectly specified.')\n",
    "\n",
    "    # 6: Generate treatment assignment W\n",
    "    w = random.binomial(size=sample_size, n=1, p=e_x)\n",
    "\n",
    "    # 7: Create observed variables Y\n",
    "    y = np.multiply(w, y_1) + np.multiply(np.ones(sample_size) - w, y_0)\n",
    "\n",
    "    # 8: Create train & test sets\n",
    "    dataset = np.concatenate(\n",
    "        (np.reshape(y, (sample_size, 1)), x_train, np.reshape(w, (sample_size, 1)), np.reshape(tau, (sample_size, 1))),\n",
    "        axis=1)\n",
    "\n",
    "    # 9: Return both sets\n",
    "    return dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create empty list to save all datasets NEW\n",
    "data = []\n",
    "for i in range(n_setups):\n",
    "    data.append([])\n",
    "\n",
    "for i in range(n_setups):\n",
    "    for r in range(n_runs):\n",
    "        data[i].append([])\n",
    "\n",
    "for i in range(n_setups):\n",
    "    for r in range(n_runs):\n",
    "        for s in range(4):\n",
    "            data[i][r].append([])\n",
    "\n",
    "for i in range(n_setups):\n",
    "    for r in range(n_runs):\n",
    "        for s in range(4):\n",
    "            for t in range(2):\n",
    "                data[i][r][s].append([])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate all datasets NEW\n",
    "\n",
    "# mean of X\n",
    "mean_X = np.zeros(d)\n",
    "\n",
    "for setup in range(n_setups):\n",
    "    print(f'Generating setup {setup + 1}')\n",
    "    for run in range(n_runs):\n",
    "        # cov, betas, beta_0 and betas_1 generated once per run\n",
    "        cov_X = np.array(mpower.cvine(d=d, alpha=0.5, beta=0.5))\n",
    "        betas_run = random.uniform(low=-1, high=1, size=d)\n",
    "        betas_0_run = random.uniform(low=-0.5, high=0.5, size=d)\n",
    "        betas_1_run = random.uniform(low=-0.5, high=0.5, size=d)\n",
    "        # start sample_size index\n",
    "        s = 0\n",
    "        for size in sample_sizes:\n",
    "            train_set = generate_data(mean=mean_X, cov=cov_X, ex=exs[setup], cate=cates[setup], sample_size=size,\n",
    "                                      betas=betas_run,\n",
    "                                      betas_0=betas_0_run, betas_1=betas_1_run)\n",
    "            test_set = generate_data(mean=mean_X, cov=cov_X, ex=exs[setup], cate=cates[setup], sample_size=test_size,\n",
    "                                     betas=betas_run,\n",
    "                                     betas_0=betas_0_run, betas_1=betas_1_run)\n",
    "            data[setup][run][s][0] = train_set  # add train-set\n",
    "            data[setup][run][s][1] = test_set  # add test-set\n",
    "            s += 1  # update index\n",
    "print('DONE')\n",
    "# it took 43 seconds # 4.4 GB of data!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[1][0][0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save as json\n",
    "file_name = \"/Users/arberimbibaj/Documents/Master Thesis ETH/DataSets /Generated/simulated_data.json\"\n",
    "f = open(file_name, 'w')\n",
    "json_obj = jsonpickle.encode(data)\n",
    "f.write(json_obj)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
