{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/arberimbibaj/dataset_example_indicatorCATE.csv', header=None, index_col=[0])\n",
    "data = data.to_numpy()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "d = len(data[0,:]) - 3\n",
    "print(N)\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train test split\n",
    "random.shuffle(data)\n",
    "training, test = data[:700,:], data[700:,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# slice dataset by treatment status\n",
    "training_control = training[training[:,26]==0]\n",
    "training_treatment = training[training[:,26]==1]\n",
    "\n",
    "# Y_train by treatment status\n",
    "Y_train_control = training_control[:,0]\n",
    "Y_train_treatment = training_treatment[:,0]\n",
    "\n",
    "# X_train by treatment status\n",
    "X_train_control = training_control[:,1:26]\n",
    "X_train_treatment = training_treatment[:,1:26]\n",
    "\n",
    "# X and Y test\n",
    "X_test = test[:,1:26]\n",
    "Y_test = test[:,0]\n",
    "\n",
    "# X_train and Y_train (no split by treatment status)\n",
    "X_train = training[:,1:26]\n",
    "Y_train = training[:,0]\n",
    "\n",
    "# W_train and W_test\n",
    "W_train = training[:,26]\n",
    "W_test = test[:,26]\n",
    "\n",
    "# tau_test\n",
    "tau_test = test[:,27]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_control"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_treatment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train_control"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train_treatment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tau_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# T-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# T-Learner (example with Random Forest)\n",
    "\n",
    "# mu_0\n",
    "t_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "t_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "t_mu_0_hat = t_learner_mu0.predict(X_test)\n",
    "\n",
    "# mu_1\n",
    "t_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "t_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "t_mu_1_hat = t_learner_mu1.predict(X_test)\n",
    "# Prediction = mu_1 - mu_0\n",
    "t_tau_hat = t_mu_1_hat - t_mu_0_hat\n",
    "t_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((t_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# S-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### S-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set training and test features for the S-Learner (it views W as no different from other X's)\n",
    "X_W_train = training[:,1:27]\n",
    "X_test_0 = np.concatenate((test[:,1:26],np.zeros((300,1))), axis=1)\n",
    "X_test_1 = np.concatenate((test[:,1:26],np.ones((300,1))), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# S-learner (example with Random Forest)\n",
    "\n",
    "# mu_x\n",
    "s_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "s_learner.fit(X_W_train,Y_train)\n",
    "\n",
    "# mu_0_hat\n",
    "s_mu_0_hat = s_learner.predict(X_test_0)\n",
    "\n",
    "# mu_1_hat\n",
    "s_mu_1_hat = s_learner.predict(X_test_1)\n",
    "\n",
    "# tau_hat\n",
    "s_tau_hat = s_mu_1_hat - s_mu_0_hat\n",
    "s_tau_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((s_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# X-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### X-Learner\n",
    "\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "x_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# compute imputed treatment effect D_0 and D_1\n",
    "# d_0\n",
    "imputed_0 = x_learner_mu1.predict(X_train_control) - Y_train_control\n",
    "\n",
    "# d_1\n",
    "imputed_1 = Y_train_treatment - x_learner_mu0.predict(X_train_treatment)\n",
    "\n",
    "# regress imputed on X\n",
    "# tau_hat_0\n",
    "x_tau_0_hat = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_tau_0_hat.fit(X_train_control ,imputed_0)\n",
    "\n",
    "# tau_hat_1\n",
    "x_tau_1_hat = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "x_tau_1_hat.fit(X_train_treatment ,imputed_1)\n",
    "\n",
    "# estimate e_x to use as g_x\n",
    "g_x_hat = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "g_x_hat.fit(X_train,W_train)\n",
    "probabilities = g_x_hat.predict_proba(X_test)\n",
    "probas_1 = probabilities[:,1]\n",
    "probas_0 = probabilities[:,0]\n",
    "\n",
    "# final estimator of tau\n",
    "x_tau_hat = probas_1 * x_tau_0_hat.predict(X_test) + probas_0 * x_tau_1_hat.predict(X_test)\n",
    "x_tau_hat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error (much lower here!)\n",
    "((x_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# R-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### R-Learner\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DR-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### DR-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RA-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### RA-Learner\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "ra_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "ra_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "ra_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "ra_pseudo_outcome = W_train*(Y_train - ra_learner_mu0.predict(X_train)) + (1 - W_train)*(ra_learner_mu1.predict(X_train) - Y_train)\n",
    "\n",
    "# tau_hat\n",
    "ra_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "ra_tau_hat_learner.fit(X_train, ra_pseudo_outcome)\n",
    "ra_tau_hat = ra_tau_hat_learner.predict(X_test)\n",
    "ra_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((ra_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PW-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### PW-Learner\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "pw_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "pw_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "pw_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "pw_pseudo_outcome = (W_train/pw_learner_e_x.predict_proba(X_train)[:,1] - (1 - W_train)/(pw_learner_e_x.predict_proba(X_train)[:,0]))*Y_train\n",
    "\n",
    "# tau_hat\n",
    "pw_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "pw_tau_hat_learner.fit(X_train, pw_pseudo_outcome)\n",
    "pw_tau_hat = pw_tau_hat_learner.predict(X_test)\n",
    "pw_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((pw_tau_hat - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# F-Learner: AKA THE SAME AS PW-LEARNER!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### F-Learner\n",
    "# mu_0 (same procedure as for t-learner, maybe can speed up process)\n",
    "f_learner_mu0 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "f_learner_mu0.fit(X_train_control,Y_train_control)\n",
    "\n",
    "# mu_1 (same procedure as for t-learner, maybe can speed up process)\n",
    "f_learner_mu1 = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "f_learner_mu1.fit(X_train_treatment,Y_train_treatment)\n",
    "\n",
    "# e_x\n",
    "f_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "f_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# ra-pseudo-outcome\n",
    "f_pseudo_outcome = (W_train/f_learner_e_x.predict_proba(X_train)[:,1] - (1 - W_train)/(f_learner_e_x.predict_proba(X_train)[:,0]))*Y_train\n",
    "\n",
    "# tau_hat\n",
    "f_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "f_tau_hat_learner.fit(X_train, pw_pseudo_outcome)\n",
    "f_tau_hat = f_tau_hat_learner.predict(X_test)\n",
    "f_tau_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "print(((f_tau_hat - tau_test)**2).mean())\n",
    "print(\"Same as for PW-Learner\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# U-Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### U-Learner\n",
    "# estimate e_x\n",
    "u_learner_e_x = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "u_learner_e_x.fit(X_train,W_train)\n",
    "\n",
    "# estimate mu_x\n",
    "u_learner_mu_x = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "u_learner_mu_x.fit(X_train,Y_train)\n",
    "\n",
    "# compute residuals\n",
    "u_learner_residuals = (Y_train - u_learner_mu_x.predict(X_train))/(W_train - u_learner_e_x.predict_proba(X_train)[:,1])\n",
    "\n",
    "# tau_hat - regress residuals on X\n",
    "u_tau_hat_learner = RandomForestRegressor(max_depth=100, random_state=0)\n",
    "u_tau_hat_learner.fit(X_train,u_learner_residuals)\n",
    "\n",
    "u_tau_hats = u_tau_hat_learner.predict(X_test)\n",
    "u_tau_hats\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "((u_tau_hats - tau_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Just some lasso tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_train = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_train = poly_train.fit_transform(X_train)\n",
    "poly_test = PolynomialFeatures(degree=4, interaction_only=False, include_bias=False)\n",
    "X_poly_test = poly_test.fit_transform(X_test)\n",
    "X_poly_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "lasso_poly = LassoCV(cv=10, random_state=0, tol=1e-2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "lasso_poly.fit(X_poly_train,Y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(f\"{total:.4f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# degree 3: 10 seconds to fit (100% cpu)\n",
    "# degree 4: 90 seconds to fit (100% cpu)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predictions = lasso_poly.predict(X_poly_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((y_predictions - Y_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# just some Neural Network test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make model\n",
    "# 3 layers with 200 units (elu activation), 2 layers with 100 units (elu activations), 1 output layer (linear activation)\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(d,)),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(units=200, activation=\"relu\", name=\"layer3\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer4\"),\n",
    "    layers.Dense(units=100, activation=\"relu\", name=\"layer5\"),\n",
    "    layers.Dense(units=1, activation=\"linear\", name=\"layer6\"),\n",
    "\n",
    "], name=\"Dense_Neural_Network\")\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, start_from_epoch=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training Model\")\n",
    "training = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=100,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[callback] # include early stopping\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Generate predictions for test samples\")\n",
    "predictions = np.reshape(model.predict(X_test),(300,))\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((predictions - Y_test)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
